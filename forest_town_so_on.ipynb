{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b1337ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kate/.local/lib/python3.8/site-packages/gluoncv/__init__.py:40: UserWarning: Both `mxnet==1.9.1` and `torch==1.10.2+cu102` are installed. You might encounter increased GPU memory footprint if both framework are used at the same time.\n",
      "  warnings.warn(f'Both `mxnet=={mx.__version__}` and `torch=={torch.__version__}` are installed. '\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from mxnet import autograd, gluon\n",
    "import gluoncv as gcv\n",
    "from gluoncv.utils import download, viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acc24903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe3fe4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/home/kate/PycharmProjects/image_prediction/images/'\n",
    "#test_dir = '../input/intel-image-classification/seg_test/seg_test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94d43c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = os.listdir(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77f3f891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['seg_train', 'seg_test', 'seg_pred']\n"
     ]
    }
   ],
   "source": [
    "print(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b54adae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/kate/PycharmProjects/image_prediction/images/seg_train/'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path+folders[0]+'/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8a61dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folders = os.listdir(os.path.join(base_path,folders[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6e21ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_folders: ['sea', 'glacier', 'forest', 'mountain', 'buildings', 'street']\n"
     ]
    }
   ],
   "source": [
    "print(f'train_folders: {train_folders}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c29f115a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Train Data Distribution-----\n",
      "Folder Name : No. of Images\n",
      "sea         : 2274\n",
      "glacier     : 2404\n",
      "forest      : 2271\n",
      "mountain    : 2512\n",
      "buildings   : 2191\n",
      "street      : 2382\n"
     ]
    }
   ],
   "source": [
    "print('----Train Data Distribution-----')\n",
    "print(f'Folder Name : No. of Images')\n",
    "for folder in train_folders:\n",
    "    print(f'{folder:11} : {len(os.listdir(os.path.join(base_path,folders[0],folder)))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7ed9c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_folders: ['sea', 'glacier', 'forest', 'mountain', 'buildings', 'street']\n"
     ]
    }
   ],
   "source": [
    "val_folders = os.listdir(os.path.join(base_path,folders[1]))\n",
    "print(f'val_folders: {val_folders}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47f9d010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Val Data Distribution-----\n",
      "Folder Name : No. of Images\n",
      "sea         : 510\n",
      "glacier     : 553\n",
      "forest      : 474\n",
      "mountain    : 525\n",
      "buildings   : 437\n",
      "street      : 501\n"
     ]
    }
   ],
   "source": [
    "print('----Val Data Distribution-----')\n",
    "print(f'Folder Name : No. of Images')\n",
    "for folder in val_folders:\n",
    "    print(f'{folder:11} : {len(os.listdir(os.path.join(base_path,folders[1],folder)))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3d7737f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_images: 7301\n",
      "First ten Images\n",
      "['21326.jpg', '5803.jpg', '12901.jpg', '7943.jpg', '677.jpg', '22049.jpg', '12033.jpg', '10434.jpg', '5229.jpg', '19065.jpg']\n"
     ]
    }
   ],
   "source": [
    "test_images = os.listdir(os.path.join(base_path,folders[2]))\n",
    "print(f'test_images: {len(test_images)}')\n",
    "print('First ten Images')\n",
    "print(test_images[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64209c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3280f23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(columns =['Names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56cdead5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Names]\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9cd32c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_folders)):\n",
    "    folder = train_folders[i]\n",
    "    a = os.listdir(os.path.join(base_path,folders[0],folder))\n",
    "    df = pd.DataFrame(a, columns =['Names'])\n",
    "    df = df.assign(Folder_Name = folder)\n",
    "    data = pd.concat([df_train, df], ignore_index=True)\n",
    "    df_train = data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "959aaf90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "      <th>Folder_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14541.jpg</td>\n",
       "      <td>sea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1543.jpg</td>\n",
       "      <td>sea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19360.jpg</td>\n",
       "      <td>sea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11382.jpg</td>\n",
       "      <td>sea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10177.jpg</td>\n",
       "      <td>sea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14029</th>\n",
       "      <td>11113.jpg</td>\n",
       "      <td>street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14030</th>\n",
       "      <td>1618.jpg</td>\n",
       "      <td>street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14031</th>\n",
       "      <td>14839.jpg</td>\n",
       "      <td>street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14032</th>\n",
       "      <td>3911.jpg</td>\n",
       "      <td>street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14033</th>\n",
       "      <td>1091.jpg</td>\n",
       "      <td>street</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14034 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Names Folder_Name\n",
       "0      14541.jpg         sea\n",
       "1       1543.jpg         sea\n",
       "2      19360.jpg         sea\n",
       "3      11382.jpg         sea\n",
       "4      10177.jpg         sea\n",
       "...          ...         ...\n",
       "14029  11113.jpg      street\n",
       "14030   1618.jpg      street\n",
       "14031  14839.jpg      street\n",
       "14032   3911.jpg      street\n",
       "14033   1091.jpg      street\n",
       "\n",
       "[14034 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9fda991c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sea', 'glacier', 'forest', 'mountain', 'buildings', 'street'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Folder_Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b76e1d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        14541.jpg\n",
       "1         1543.jpg\n",
       "2        19360.jpg\n",
       "3        11382.jpg\n",
       "4        10177.jpg\n",
       "           ...    \n",
       "14029    11113.jpg\n",
       "14030     1618.jpg\n",
       "14031    14839.jpg\n",
       "14032     3911.jpg\n",
       "14033     1091.jpg\n",
       "Name: Names, Length: 14034, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b929b19a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['seg_train', 'seg_test', 'seg_pred']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23e9284d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        /home/kate/PycharmProjects/image_prediction/im...\n",
       "1        /home/kate/PycharmProjects/image_prediction/im...\n",
       "2        /home/kate/PycharmProjects/image_prediction/im...\n",
       "3        /home/kate/PycharmProjects/image_prediction/im...\n",
       "4        /home/kate/PycharmProjects/image_prediction/im...\n",
       "                               ...                        \n",
       "14029    /home/kate/PycharmProjects/image_prediction/im...\n",
       "14030    /home/kate/PycharmProjects/image_prediction/im...\n",
       "14031    /home/kate/PycharmProjects/image_prediction/im...\n",
       "14032    /home/kate/PycharmProjects/image_prediction/im...\n",
       "14033    /home/kate/PycharmProjects/image_prediction/im...\n",
       "Name: Folder_Name, Length: 14034, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path+folders[0]+'/'+df_train['Folder_Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d127faae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['folder_for_file'] = base_path+folders[0]+'/'+ df_train['Folder_Name']+'/'+df_train['Names']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14112795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "      <th>Folder_Name</th>\n",
       "      <th>folder_for_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14541.jpg</td>\n",
       "      <td>sea</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1543.jpg</td>\n",
       "      <td>sea</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19360.jpg</td>\n",
       "      <td>sea</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11382.jpg</td>\n",
       "      <td>sea</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10177.jpg</td>\n",
       "      <td>sea</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14029</th>\n",
       "      <td>11113.jpg</td>\n",
       "      <td>street</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14030</th>\n",
       "      <td>1618.jpg</td>\n",
       "      <td>street</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14031</th>\n",
       "      <td>14839.jpg</td>\n",
       "      <td>street</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14032</th>\n",
       "      <td>3911.jpg</td>\n",
       "      <td>street</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14033</th>\n",
       "      <td>1091.jpg</td>\n",
       "      <td>street</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14034 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Names Folder_Name  \\\n",
       "0      14541.jpg         sea   \n",
       "1       1543.jpg         sea   \n",
       "2      19360.jpg         sea   \n",
       "3      11382.jpg         sea   \n",
       "4      10177.jpg         sea   \n",
       "...          ...         ...   \n",
       "14029  11113.jpg      street   \n",
       "14030   1618.jpg      street   \n",
       "14031  14839.jpg      street   \n",
       "14032   3911.jpg      street   \n",
       "14033   1091.jpg      street   \n",
       "\n",
       "                                         folder_for_file  \n",
       "0      /home/kate/PycharmProjects/image_prediction/im...  \n",
       "1      /home/kate/PycharmProjects/image_prediction/im...  \n",
       "2      /home/kate/PycharmProjects/image_prediction/im...  \n",
       "3      /home/kate/PycharmProjects/image_prediction/im...  \n",
       "4      /home/kate/PycharmProjects/image_prediction/im...  \n",
       "...                                                  ...  \n",
       "14029  /home/kate/PycharmProjects/image_prediction/im...  \n",
       "14030  /home/kate/PycharmProjects/image_prediction/im...  \n",
       "14031  /home/kate/PycharmProjects/image_prediction/im...  \n",
       "14032  /home/kate/PycharmProjects/image_prediction/im...  \n",
       "14033  /home/kate/PycharmProjects/image_prediction/im...  \n",
       "\n",
       "[14034 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec018476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_rating(folder):\n",
    "    if folder == 'glacier':\n",
    "        return (2)\n",
    "    elif folder == 'sea':\n",
    "        return (4)\n",
    "    elif folder == 'buildings':\n",
    "        return (0)\n",
    "    elif folder == 'forest':\n",
    "        return (1)\n",
    "    elif folder == 'street':\n",
    "        return (5)\n",
    "    \n",
    "    elif folder == 'mountain':\n",
    "        return (3)\n",
    "        \n",
    "df_train['label'] = df_train.Folder_Name.apply(lambda x: custom_rating(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4621aee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "      <th>Folder_Name</th>\n",
       "      <th>folder_for_file</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14541.jpg</td>\n",
       "      <td>sea</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1543.jpg</td>\n",
       "      <td>sea</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19360.jpg</td>\n",
       "      <td>sea</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11382.jpg</td>\n",
       "      <td>sea</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10177.jpg</td>\n",
       "      <td>sea</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14029</th>\n",
       "      <td>11113.jpg</td>\n",
       "      <td>street</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14030</th>\n",
       "      <td>1618.jpg</td>\n",
       "      <td>street</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14031</th>\n",
       "      <td>14839.jpg</td>\n",
       "      <td>street</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14032</th>\n",
       "      <td>3911.jpg</td>\n",
       "      <td>street</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14033</th>\n",
       "      <td>1091.jpg</td>\n",
       "      <td>street</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14034 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Names Folder_Name  \\\n",
       "0      14541.jpg         sea   \n",
       "1       1543.jpg         sea   \n",
       "2      19360.jpg         sea   \n",
       "3      11382.jpg         sea   \n",
       "4      10177.jpg         sea   \n",
       "...          ...         ...   \n",
       "14029  11113.jpg      street   \n",
       "14030   1618.jpg      street   \n",
       "14031  14839.jpg      street   \n",
       "14032   3911.jpg      street   \n",
       "14033   1091.jpg      street   \n",
       "\n",
       "                                         folder_for_file  label  \n",
       "0      /home/kate/PycharmProjects/image_prediction/im...      4  \n",
       "1      /home/kate/PycharmProjects/image_prediction/im...      4  \n",
       "2      /home/kate/PycharmProjects/image_prediction/im...      4  \n",
       "3      /home/kate/PycharmProjects/image_prediction/im...      4  \n",
       "4      /home/kate/PycharmProjects/image_prediction/im...      4  \n",
       "...                                                  ...    ...  \n",
       "14029  /home/kate/PycharmProjects/image_prediction/im...      5  \n",
       "14030  /home/kate/PycharmProjects/image_prediction/im...      5  \n",
       "14031  /home/kate/PycharmProjects/image_prediction/im...      5  \n",
       "14032  /home/kate/PycharmProjects/image_prediction/im...      5  \n",
       "14033  /home/kate/PycharmProjects/image_prediction/im...      5  \n",
       "\n",
       "[14034 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34b239c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af65bc49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/kate/PycharmProjects/image_prediction/images/seg_train/sea/14541.jpg'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.folder_for_file[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51b13355",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 17:07:22.554912: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-14 17:07:22.554939: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import autogluon.core as ag\n",
    "from autogluon.vision import ImageDataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "81394e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "015ab012",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogluon.core as ag\n",
    "from autogluon.vision import ImagePredictor, ImageDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9164dfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = df_train[['folder_for_file','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f21da225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder_for_file</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14029</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14030</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14031</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14032</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14033</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14034 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         folder_for_file  label\n",
       "0      /home/kate/PycharmProjects/image_prediction/im...      4\n",
       "1      /home/kate/PycharmProjects/image_prediction/im...      4\n",
       "2      /home/kate/PycharmProjects/image_prediction/im...      4\n",
       "3      /home/kate/PycharmProjects/image_prediction/im...      4\n",
       "4      /home/kate/PycharmProjects/image_prediction/im...      4\n",
       "...                                                  ...    ...\n",
       "14029  /home/kate/PycharmProjects/image_prediction/im...      5\n",
       "14030  /home/kate/PycharmProjects/image_prediction/im...      5\n",
       "14031  /home/kate/PycharmProjects/image_prediction/im...      5\n",
       "14032  /home/kate/PycharmProjects/image_prediction/im...      5\n",
       "14033  /home/kate/PycharmProjects/image_prediction/im...      5\n",
       "\n",
       "[14034 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c0839b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder_for_file</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14029</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14030</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14031</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14032</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14033</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14034 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         folder_for_file  label\n",
       "0      /home/kate/PycharmProjects/image_prediction/im...      4\n",
       "1      /home/kate/PycharmProjects/image_prediction/im...      4\n",
       "2      /home/kate/PycharmProjects/image_prediction/im...      4\n",
       "3      /home/kate/PycharmProjects/image_prediction/im...      4\n",
       "4      /home/kate/PycharmProjects/image_prediction/im...      4\n",
       "...                                                  ...    ...\n",
       "14029  /home/kate/PycharmProjects/image_prediction/im...      5\n",
       "14030  /home/kate/PycharmProjects/image_prediction/im...      5\n",
       "14031  /home/kate/PycharmProjects/image_prediction/im...      5\n",
       "14032  /home/kate/PycharmProjects/image_prediction/im...      5\n",
       "14033  /home/kate/PycharmProjects/image_prediction/im...      5\n",
       "\n",
       "[14034 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5b67faa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.rename(columns={\"folder_for_file\": \"image\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "29af2877",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = ImagePredictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e1b92c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`time_limit=auto` set to `time_limit=7200`.\n",
      "Converting raw DataFrame to ImageDataset...\n",
      "Detected 6 unique classes: [0, 1, 2, 3, 4, 5]\n",
      "If you feel the `classes` is inaccurate, please construct the dataset explicitly, e.g. train_data = ImageDataset(train_data, classes=[\"foo\", \"bar\"])\n",
      "Randomly split train_data into train[12630]/validation[1404] splits.\n",
      "The number of requested GPUs is greater than the number of available GPUs.Reduce the number to 1\n",
      "Starting fit without HPO\n",
      "modified configs(<old> != <new>): {\n",
      "root.img_cls.model   resnet101 != resnet50\n",
      "root.train.batch_size 32 != 16\n",
      "root.train.early_stop_max_value 1.0 != inf\n",
      "root.train.early_stop_patience -1 != 10\n",
      "root.train.epochs    200 != 2\n",
      "root.train.early_stop_baseline 0.0 != -inf\n",
      "root.misc.seed       42 != 171\n",
      "root.misc.num_workers 4 != 12\n",
      "}\n",
      "Saved config to /home/kate/PycharmProjects/image_prediction/b2e55476/.trial_0/config.yaml\n",
      "No gpu detected, fallback to cpu. You can ignore this warning if this is intended.\n",
      "Model resnet50 created, param count:                                         23520326\n",
      "AMP not enabled. Training in float32.\n",
      "Disable EMA as it is not supported for now.\n",
      "Start training from [Epoch 0]\n",
      "Epoch[0] Batch [49]\tSpeed: 4.962660 samples/sec\taccuracy=0.228750\tlr=0.000100\n",
      "Epoch[0] Batch [99]\tSpeed: 8.326998 samples/sec\taccuracy=0.243750\tlr=0.000100\n",
      "Epoch[0] Batch [149]\tSpeed: 8.578162 samples/sec\taccuracy=0.266250\tlr=0.000100\n",
      "Epoch[0] Batch [199]\tSpeed: 8.432027 samples/sec\taccuracy=0.282813\tlr=0.000100\n",
      "Epoch[0] Batch [249]\tSpeed: 7.898694 samples/sec\taccuracy=0.291000\tlr=0.000100\n",
      "Epoch[0] Batch [299]\tSpeed: 7.779939 samples/sec\taccuracy=0.305000\tlr=0.000100\n",
      "Epoch[0] Batch [349]\tSpeed: 7.756461 samples/sec\taccuracy=0.316607\tlr=0.000100\n",
      "Epoch[0] Batch [399]\tSpeed: 8.052969 samples/sec\taccuracy=0.327969\tlr=0.000100\n",
      "Epoch[0] Batch [449]\tSpeed: 7.767020 samples/sec\taccuracy=0.339722\tlr=0.000100\n",
      "Epoch[0] Batch [499]\tSpeed: 7.765967 samples/sec\taccuracy=0.348750\tlr=0.000100\n",
      "Epoch[0] Batch [549]\tSpeed: 8.221617 samples/sec\taccuracy=0.357159\tlr=0.000100\n",
      "Epoch[0] Batch [599]\tSpeed: 8.171309 samples/sec\taccuracy=0.366458\tlr=0.000100\n",
      "Epoch[0] Batch [649]\tSpeed: 7.989175 samples/sec\taccuracy=0.373462\tlr=0.000100\n",
      "Epoch[0] Batch [699]\tSpeed: 7.971594 samples/sec\taccuracy=0.379464\tlr=0.000100\n",
      "Epoch[0] Batch [749]\tSpeed: 7.594283 samples/sec\taccuracy=0.388250\tlr=0.000100\n",
      "[Epoch 0] training: accuracy=0.394724\n",
      "[Epoch 0] speed: 7 samples/sec\ttime cost: 1636.490294\n",
      "[Epoch 0] validation: top1=0.621795 top5=0.994302\n",
      "[Epoch 0] Current best top-1: 0.621795 vs previous -inf, saved to /home/kate/PycharmProjects/image_prediction/b2e55476/.trial_0/best_checkpoint.pkl\n",
      "Epoch[1] Batch [49]\tSpeed: 7.680618 samples/sec\taccuracy=0.550000\tlr=0.003400\n",
      "Epoch[1] Batch [99]\tSpeed: 8.086111 samples/sec\taccuracy=0.581875\tlr=0.003400\n",
      "Epoch[1] Batch [149]\tSpeed: 7.988932 samples/sec\taccuracy=0.615000\tlr=0.003400\n",
      "Epoch[1] Batch [199]\tSpeed: 8.305128 samples/sec\taccuracy=0.635312\tlr=0.003400\n",
      "Epoch[1] Batch [249]\tSpeed: 8.433301 samples/sec\taccuracy=0.650500\tlr=0.003400\n",
      "Epoch[1] Batch [299]\tSpeed: 8.597577 samples/sec\taccuracy=0.665833\tlr=0.003400\n",
      "Epoch[1] Batch [349]\tSpeed: 8.500907 samples/sec\taccuracy=0.680714\tlr=0.003400\n",
      "Epoch[1] Batch [399]\tSpeed: 8.404679 samples/sec\taccuracy=0.693125\tlr=0.003400\n",
      "Epoch[1] Batch [449]\tSpeed: 8.544335 samples/sec\taccuracy=0.698194\tlr=0.003400\n",
      "Epoch[1] Batch [499]\tSpeed: 8.596643 samples/sec\taccuracy=0.705625\tlr=0.003400\n",
      "Epoch[1] Batch [549]\tSpeed: 8.208987 samples/sec\taccuracy=0.710568\tlr=0.003400\n",
      "Epoch[1] Batch [599]\tSpeed: 8.345486 samples/sec\taccuracy=0.715729\tlr=0.003400\n",
      "Epoch[1] Batch [649]\tSpeed: 7.751175 samples/sec\taccuracy=0.719904\tlr=0.003400\n",
      "Epoch[1] Batch [699]\tSpeed: 7.962169 samples/sec\taccuracy=0.723661\tlr=0.003400\n",
      "Epoch[1] Batch [749]\tSpeed: 7.926440 samples/sec\taccuracy=0.728250\tlr=0.003400\n",
      "[Epoch 1] training: accuracy=0.731226\n",
      "[Epoch 1] speed: 8 samples/sec\ttime cost: 1538.737399\n",
      "[Epoch 1] validation: top1=0.865385 top5=0.997863\n",
      "[Epoch 1] Current best top-1: 0.865385 vs previous 0.621795, saved to /home/kate/PycharmProjects/image_prediction/b2e55476/.trial_0/best_checkpoint.pkl\n",
      "Applying the state from the best checkpoint...\n",
      "Finished, total runtime is 3301.80 s\n",
      "{ 'best_config': { 'batch_size': 16,\n",
      "                   'dist_ip_addrs': None,\n",
      "                   'early_stop_baseline': -inf,\n",
      "                   'early_stop_max_value': inf,\n",
      "                   'early_stop_patience': 10,\n",
      "                   'epochs': 2,\n",
      "                   'final_fit': False,\n",
      "                   'gpus': [0],\n",
      "                   'lr': 0.01,\n",
      "                   'model': 'resnet50',\n",
      "                   'ngpus_per_trial': 8,\n",
      "                   'nthreads_per_trial': 128,\n",
      "                   'num_workers': 12,\n",
      "                   'searcher': 'random',\n",
      "                   'seed': 171,\n",
      "                   'time_limits': 7200},\n",
      "  'total_time': 3281.4349839687347,\n",
      "  'train_acc': 0.7312262357414449,\n",
      "  'valid_acc': 0.865384615724243}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.vision.predictor.predictor.ImagePredictor at 0x7f1b4d856af0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.fit(train_dataset, hyperparameters={'epochs': 2})  # you can trust the default config, we reduce the # epoch to save some build time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c65f5f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ag.Categorical('resnet18_v1b', 'mobilenetv3_small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "896556dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "lr = ag.Categorical(1e-2, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8158e7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters={'model': model, 'batch_size': batch_size, 'lr': lr, 'epochs': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e05ac6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ImagePredictor sets accuracy as default eval_metric for classification problems.\n",
      "Converting raw DataFrame to ImageDataset...\n",
      "Detected 6 unique classes: [0, 1, 2, 3, 4, 5]\n",
      "If you feel the `classes` is inaccurate, please construct the dataset explicitly, e.g. train_data = ImageDataset(train_data, classes=[\"foo\", \"bar\"])\n",
      "Randomly split train_data into train[12630]/validation[1404] splits.\n",
      "The number of requested GPUs is greater than the number of available GPUs.Reduce the number to 1\n",
      "Starting HPO experiments\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eec8cbb35394ae9b9d1817893bef634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=============================================================================\n",
      "WARNING: Using MXNet models in ImagePredictor is deprecated as of v0.4.0 and may contain various bugs and issues!\n",
      "In v0.5.0, ImagePredictor will no longer support training MXNet models. Please consider switching to specifying Torch models instead.\n",
      "Users should ensure they update their code that depends on ImagePredictor when upgrading to future AutoGluon releases.\n",
      "For more information, refer to this GitHub issue: https://github.com/awslabs/autogluon/issues/1560\n",
      "=============================================================================\n",
      "\n",
      "modified configs(<old> != <new>): {\n",
      "root.img_cls.model   resnet50_v1 != resnet18_v1b\n",
      "root.train.batch_size 128 != 8\n",
      "root.train.rec_train ~/.mxnet/datasets/imagenet/rec/train.rec != auto\n",
      "root.train.early_stop_max_value 1.0 != inf\n",
      "root.train.early_stop_patience -1 != 10\n",
      "root.train.rec_train_idx ~/.mxnet/datasets/imagenet/rec/train.idx != auto\n",
      "root.train.rec_val   ~/.mxnet/datasets/imagenet/rec/val.rec != auto\n",
      "root.train.data_dir  ~/.mxnet/datasets/imagenet != auto\n",
      "root.train.epochs    10 != 2\n",
      "root.train.num_training_samples 1281167 != -1\n",
      "root.train.early_stop_baseline 0.0 != -inf\n",
      "root.train.lr        0.1 != 0.01\n",
      "root.train.rec_val_idx ~/.mxnet/datasets/imagenet/rec/val.idx != auto\n",
      "root.train.num_workers 4 != 12\n",
      "root.valid.num_workers 4 != 12\n",
      "root.valid.batch_size 128 != 8\n",
      "}\n",
      "Saved config to /home/kate/PycharmProjects/image_prediction/2f1ad510/.trial_0/config.yaml\n",
      "[No gpu detected, fallback to cpu. You can ignore this warning if this is intended.\n",
      "18:13:27] ../src/imperative/./imperative_utils.h:93: GPU support is disabled. Compile MXNet with USE_CUDA=1 to enable GPU support.\n",
      "Start training from [Epoch 0]\n",
      "Epoch[0] Batch [49]\tSpeed: 21.234290 samples/sec\taccuracy=0.327500\tlr=0.010000\n",
      "Epoch[0] Batch [99]\tSpeed: 25.148704 samples/sec\taccuracy=0.462500\tlr=0.010000\n",
      "Epoch[0] Batch [149]\tSpeed: 25.516834 samples/sec\taccuracy=0.522500\tlr=0.010000\n",
      "Epoch[0] Batch [199]\tSpeed: 24.155886 samples/sec\taccuracy=0.567500\tlr=0.010000\n",
      "Epoch[0] Batch [249]\tSpeed: 23.577094 samples/sec\taccuracy=0.585500\tlr=0.010000\n",
      "Epoch[0] Batch [299]\tSpeed: 23.296218 samples/sec\taccuracy=0.605833\tlr=0.010000\n",
      "Epoch[0] Batch [349]\tSpeed: 20.574714 samples/sec\taccuracy=0.620357\tlr=0.010000\n",
      "Epoch[0] Batch [399]\tSpeed: 22.533750 samples/sec\taccuracy=0.634687\tlr=0.010000\n",
      "Epoch[0] Batch [449]\tSpeed: 22.084308 samples/sec\taccuracy=0.648333\tlr=0.010000\n",
      "Epoch[0] Batch [499]\tSpeed: 20.095024 samples/sec\taccuracy=0.653750\tlr=0.010000\n",
      "Epoch[0] Batch [549]\tSpeed: 20.064374 samples/sec\taccuracy=0.660227\tlr=0.010000\n",
      "Epoch[0] Batch [599]\tSpeed: 20.062097 samples/sec\taccuracy=0.670833\tlr=0.010000\n",
      "Epoch[0] Batch [649]\tSpeed: 20.581628 samples/sec\taccuracy=0.677885\tlr=0.010000\n",
      "Epoch[0] Batch [699]\tSpeed: 21.693759 samples/sec\taccuracy=0.683393\tlr=0.010000\n",
      "Epoch[0] Batch [749]\tSpeed: 21.601527 samples/sec\taccuracy=0.687167\tlr=0.010000\n",
      "Epoch[0] Batch [799]\tSpeed: 21.621161 samples/sec\taccuracy=0.692187\tlr=0.010000\n",
      "Epoch[0] Batch [849]\tSpeed: 21.999956 samples/sec\taccuracy=0.698529\tlr=0.010000\n",
      "Epoch[0] Batch [899]\tSpeed: 23.387934 samples/sec\taccuracy=0.701806\tlr=0.010000\n",
      "Epoch[0] Batch [949]\tSpeed: 24.764077 samples/sec\taccuracy=0.703158\tlr=0.010000\n",
      "Epoch[0] Batch [999]\tSpeed: 23.578977 samples/sec\taccuracy=0.708375\tlr=0.010000\n",
      "Epoch[0] Batch [1049]\tSpeed: 20.275564 samples/sec\taccuracy=0.712976\tlr=0.010000\n",
      "Epoch[0] Batch [1099]\tSpeed: 21.286260 samples/sec\taccuracy=0.715795\tlr=0.010000\n",
      "Epoch[0] Batch [1149]\tSpeed: 21.928639 samples/sec\taccuracy=0.717826\tlr=0.010000\n",
      "Epoch[0] Batch [1199]\tSpeed: 24.998758 samples/sec\taccuracy=0.719271\tlr=0.010000\n",
      "Epoch[0] Batch [1249]\tSpeed: 25.075249 samples/sec\taccuracy=0.723600\tlr=0.010000\n",
      "Epoch[0] Batch [1299]\tSpeed: 21.754536 samples/sec\taccuracy=0.724423\tlr=0.010000\n",
      "Epoch[0] Batch [1349]\tSpeed: 21.389692 samples/sec\taccuracy=0.726481\tlr=0.010000\n",
      "Epoch[0] Batch [1399]\tSpeed: 22.568442 samples/sec\taccuracy=0.727232\tlr=0.010000\n",
      "Epoch[0] Batch [1449]\tSpeed: 25.123810 samples/sec\taccuracy=0.728879\tlr=0.010000\n",
      "Epoch[0] Batch [1499]\tSpeed: 23.097441 samples/sec\taccuracy=0.729583\tlr=0.010000\n",
      "Epoch[0] Batch [1549]\tSpeed: 23.586456 samples/sec\taccuracy=0.731210\tlr=0.010000\n",
      "[Epoch 0] training: accuracy=0.732811\n",
      "[Epoch 0] speed: 22 samples/sec\ttime cost: 563.463448\n",
      "[Epoch 0] validation: top1=0.895299 top5=0.999288\n",
      "[Epoch 0] Current best top-1: 0.895299 vs previous -inf, saved to /home/kate/PycharmProjects/image_prediction/2f1ad510/.trial_0/best_checkpoint.pkl\n",
      "`time_limit=599.9797806739807` reached, exit early...\n",
      "Applying the state from the best checkpoint...\n",
      "[18:23:35] ../src/imperative/./imperative_utils.h:93: GPU support is disabled. Compile MXNet with USE_CUDA=1 to enable GPU support.\n",
      "\tStopping HPO to satisfy time limit...\n",
      "=============================================================================\n",
      "WARNING: Using MXNet models in ImagePredictor is deprecated as of v0.4.0 and may contain various bugs and issues!\n",
      "In v0.5.0, ImagePredictor will no longer support training MXNet models. Please consider switching to specifying Torch models instead.\n",
      "Users should ensure they update their code that depends on ImagePredictor when upgrading to future AutoGluon releases.\n",
      "For more information, refer to this GitHub issue: https://github.com/awslabs/autogluon/issues/1560\n",
      "=============================================================================\n",
      "\n",
      "[18:23:36] ../src/imperative/./imperative_utils.h:93: GPU support is disabled. Compile MXNet with USE_CUDA=1 to enable GPU support.\n",
      "Saving Training Curve in /home/kate/PycharmProjects/image_prediction/2f1ad510/plot_training_curves.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finished, total runtime is 609.62 s\n",
      "{ 'best_config': { 'estimator': <class 'gluoncv.auto.estimators.image_classification.image_classification.ImageClassificationEstimator'>,\n",
      "                   'gpus': [0],\n",
      "                   'img_cls': { 'batch_norm': False,\n",
      "                                'last_gamma': False,\n",
      "                                'model': 'resnet18_v1b',\n",
      "                                'use_gn': False,\n",
      "                                'use_pretrained': True,\n",
      "                                'use_se': False},\n",
      "                   'train': { 'batch_size': 8,\n",
      "                              'crop_ratio': 0.875,\n",
      "                              'data_dir': 'auto',\n",
      "                              'dtype': 'float32',\n",
      "                              'early_stop_baseline': -inf,\n",
      "                              'early_stop_max_value': inf,\n",
      "                              'early_stop_min_delta': 0.001,\n",
      "                              'early_stop_patience': 10,\n",
      "                              'epochs': 2,\n",
      "                              'hard_weight': 0.5,\n",
      "                              'input_size': 224,\n",
      "                              'label_smoothing': False,\n",
      "                              'log_interval': 50,\n",
      "                              'lr': 0.01,\n",
      "                              'lr_decay': 0.1,\n",
      "                              'lr_decay_epoch': '40, 60',\n",
      "                              'lr_decay_period': 0,\n",
      "                              'lr_mode': 'step',\n",
      "                              'mixup': False,\n",
      "                              'mixup_alpha': 0.2,\n",
      "                              'mixup_off_epoch': 0,\n",
      "                              'mode': '',\n",
      "                              'momentum': 0.9,\n",
      "                              'no_wd': False,\n",
      "                              'num_training_samples': -1,\n",
      "                              'num_workers': 12,\n",
      "                              'output_lr_mult': 0.1,\n",
      "                              'pretrained_base': True,\n",
      "                              'rec_train': 'auto',\n",
      "                              'rec_train_idx': 'auto',\n",
      "                              'rec_val': 'auto',\n",
      "                              'rec_val_idx': 'auto',\n",
      "                              'resume_epoch': 0,\n",
      "                              'start_epoch': 0,\n",
      "                              'teacher': None,\n",
      "                              'temperature': 20,\n",
      "                              'transfer_lr_mult': 0.01,\n",
      "                              'use_rec': False,\n",
      "                              'warmup_epochs': 0,\n",
      "                              'warmup_lr': 0.0,\n",
      "                              'wd': 0.0001},\n",
      "                   'valid': {'batch_size': 8, 'num_workers': 12}},\n",
      "  'total_time': 609.4358172416687,\n",
      "  'train_acc': 0.7328105196451205,\n",
      "  'valid_acc': 0.8952991452991453}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 val acc: 0.895\n"
     ]
    }
   ],
   "source": [
    "hyperparameters={'model': model, 'batch_size': batch_size, 'lr': lr, 'epochs': 2}\n",
    "predictor = ImagePredictor()\n",
    "predictor.fit(train_dataset, time_limit=60*10, hyperparameters=hyperparameters,\n",
    "              hyperparameter_tune_kwargs={'num_trials': 2})\n",
    "print('Top-1 val acc: %.3f' % predictor.fit_summary()['valid_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ae750201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 train acc: 0.733, val acc: 0.895\n"
     ]
    }
   ],
   "source": [
    "fit_result = predictor.fit_summary()\n",
    "print('Top-1 train acc: %.3f, val acc: %.3f' %(fit_result['train_acc'], fit_result['valid_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9509500c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'seg_pred'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3b359479",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_images = os.listdir(os.path.join(base_path,folders[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "53e23641",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.DataFrame(pred_images, columns =['Names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "184a351d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21326.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5803.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12901.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7943.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>677.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7296</th>\n",
       "      <td>14821.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7297</th>\n",
       "      <td>10855.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7298</th>\n",
       "      <td>4236.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7299</th>\n",
       "      <td>13136.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7300</th>\n",
       "      <td>23857.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7301 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Names\n",
       "0     21326.jpg\n",
       "1      5803.jpg\n",
       "2     12901.jpg\n",
       "3      7943.jpg\n",
       "4       677.jpg\n",
       "...         ...\n",
       "7296  14821.jpg\n",
       "7297  10855.jpg\n",
       "7298   4236.jpg\n",
       "7299  13136.jpg\n",
       "7300  23857.jpg\n",
       "\n",
       "[7301 rows x 1 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "df0703f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       /home/kate/PycharmProjects/image_prediction/im...\n",
       "1       /home/kate/PycharmProjects/image_prediction/im...\n",
       "2       /home/kate/PycharmProjects/image_prediction/im...\n",
       "3       /home/kate/PycharmProjects/image_prediction/im...\n",
       "4       /home/kate/PycharmProjects/image_prediction/im...\n",
       "                              ...                        \n",
       "7296    /home/kate/PycharmProjects/image_prediction/im...\n",
       "7297    /home/kate/PycharmProjects/image_prediction/im...\n",
       "7298    /home/kate/PycharmProjects/image_prediction/im...\n",
       "7299    /home/kate/PycharmProjects/image_prediction/im...\n",
       "7300    /home/kate/PycharmProjects/image_prediction/im...\n",
       "Name: Names, Length: 7301, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path+folders[2]+'/'+df_pred['Names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "39c87775",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred['image'] = base_path+folders[2]+'/'+df_pred['Names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "508868b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/kate/PycharmProjects/image_prediction/images/seg_pred/21326.jpg'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.image[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ad4ab2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = predictor.predict(df_pred.image[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2e215774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/kate/PycharmProjects/image_prediction/images/seg_pred/5803.jpg'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.image[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "34078d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = predictor.predict(df_pred.image[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "304a02c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "abdb758b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folders = os.listdir(os.path.join(base_path,folders[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "afadb354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sea', 'glacier', 'forest', 'mountain', 'buildings', 'street']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3416e246",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(columns =['Names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e167ddc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_folders)):\n",
    "    folder = test_folders[i]\n",
    "    a = os.listdir(os.path.join(base_path,folders[1],folder))\n",
    "    df = pd.DataFrame(a, columns =['Names'])\n",
    "    df = df.assign(Folder_Name = folder)\n",
    "    data = pd.concat([df_test, df], ignore_index=True)\n",
    "    df_test = data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "62de6a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "      <th>Folder_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20869.jpg</td>\n",
       "      <td>sea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24180.jpg</td>\n",
       "      <td>sea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20300.jpg</td>\n",
       "      <td>sea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21730.jpg</td>\n",
       "      <td>sea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20722.jpg</td>\n",
       "      <td>sea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>23155.jpg</td>\n",
       "      <td>street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>21062.jpg</td>\n",
       "      <td>street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>22786.jpg</td>\n",
       "      <td>street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>23586.jpg</td>\n",
       "      <td>street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>23795.jpg</td>\n",
       "      <td>street</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Names Folder_Name\n",
       "0     20869.jpg         sea\n",
       "1     24180.jpg         sea\n",
       "2     20300.jpg         sea\n",
       "3     21730.jpg         sea\n",
       "4     20722.jpg         sea\n",
       "...         ...         ...\n",
       "2995  23155.jpg      street\n",
       "2996  21062.jpg      street\n",
       "2997  22786.jpg      street\n",
       "2998  23586.jpg      street\n",
       "2999  23795.jpg      street\n",
       "\n",
       "[3000 rows x 2 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "35b69f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['folder_for_file'] = base_path+folders[1]+'/'+ df_test['Folder_Name']+'/'+df_test['Names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "64a64dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "      <th>Folder_Name</th>\n",
       "      <th>folder_for_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20869.jpg</td>\n",
       "      <td>sea</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24180.jpg</td>\n",
       "      <td>sea</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20300.jpg</td>\n",
       "      <td>sea</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21730.jpg</td>\n",
       "      <td>sea</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20722.jpg</td>\n",
       "      <td>sea</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>23155.jpg</td>\n",
       "      <td>street</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>21062.jpg</td>\n",
       "      <td>street</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>22786.jpg</td>\n",
       "      <td>street</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>23586.jpg</td>\n",
       "      <td>street</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>23795.jpg</td>\n",
       "      <td>street</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Names Folder_Name                                    folder_for_file\n",
       "0     20869.jpg         sea  /home/kate/PycharmProjects/image_prediction/im...\n",
       "1     24180.jpg         sea  /home/kate/PycharmProjects/image_prediction/im...\n",
       "2     20300.jpg         sea  /home/kate/PycharmProjects/image_prediction/im...\n",
       "3     21730.jpg         sea  /home/kate/PycharmProjects/image_prediction/im...\n",
       "4     20722.jpg         sea  /home/kate/PycharmProjects/image_prediction/im...\n",
       "...         ...         ...                                                ...\n",
       "2995  23155.jpg      street  /home/kate/PycharmProjects/image_prediction/im...\n",
       "2996  21062.jpg      street  /home/kate/PycharmProjects/image_prediction/im...\n",
       "2997  22786.jpg      street  /home/kate/PycharmProjects/image_prediction/im...\n",
       "2998  23586.jpg      street  /home/kate/PycharmProjects/image_prediction/im...\n",
       "2999  23795.jpg      street  /home/kate/PycharmProjects/image_prediction/im...\n",
       "\n",
       "[3000 rows x 3 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a2cdd946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_rating(folder):\n",
    "    if folder == 'glacier':\n",
    "        return (2)\n",
    "    elif folder == 'sea':\n",
    "        return (4)\n",
    "    elif folder == 'buildings':\n",
    "        return (0)\n",
    "    elif folder == 'forest':\n",
    "        return (1)\n",
    "    elif folder == 'street':\n",
    "        return (5)\n",
    "    \n",
    "    elif folder == 'mountain':\n",
    "        return (3)\n",
    "        \n",
    "df_test['label'] = df_test.Folder_Name.apply(lambda x: custom_rating(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "75ef5208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "      <th>Folder_Name</th>\n",
       "      <th>folder_for_file</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20869.jpg</td>\n",
       "      <td>sea</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24180.jpg</td>\n",
       "      <td>sea</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20300.jpg</td>\n",
       "      <td>sea</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21730.jpg</td>\n",
       "      <td>sea</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20722.jpg</td>\n",
       "      <td>sea</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>23155.jpg</td>\n",
       "      <td>street</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>21062.jpg</td>\n",
       "      <td>street</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>22786.jpg</td>\n",
       "      <td>street</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>23586.jpg</td>\n",
       "      <td>street</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>23795.jpg</td>\n",
       "      <td>street</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Names Folder_Name  \\\n",
       "0     20869.jpg         sea   \n",
       "1     24180.jpg         sea   \n",
       "2     20300.jpg         sea   \n",
       "3     21730.jpg         sea   \n",
       "4     20722.jpg         sea   \n",
       "...         ...         ...   \n",
       "2995  23155.jpg      street   \n",
       "2996  21062.jpg      street   \n",
       "2997  22786.jpg      street   \n",
       "2998  23586.jpg      street   \n",
       "2999  23795.jpg      street   \n",
       "\n",
       "                                        folder_for_file  label  \n",
       "0     /home/kate/PycharmProjects/image_prediction/im...      4  \n",
       "1     /home/kate/PycharmProjects/image_prediction/im...      4  \n",
       "2     /home/kate/PycharmProjects/image_prediction/im...      4  \n",
       "3     /home/kate/PycharmProjects/image_prediction/im...      4  \n",
       "4     /home/kate/PycharmProjects/image_prediction/im...      4  \n",
       "...                                                 ...    ...  \n",
       "2995  /home/kate/PycharmProjects/image_prediction/im...      5  \n",
       "2996  /home/kate/PycharmProjects/image_prediction/im...      5  \n",
       "2997  /home/kate/PycharmProjects/image_prediction/im...      5  \n",
       "2998  /home/kate/PycharmProjects/image_prediction/im...      5  \n",
       "2999  /home/kate/PycharmProjects/image_prediction/im...      5  \n",
       "\n",
       "[3000 rows x 4 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9517cbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = df_test[['folder_for_file','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0333f9b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder_for_file</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        folder_for_file  label\n",
       "0     /home/kate/PycharmProjects/image_prediction/im...      4\n",
       "1     /home/kate/PycharmProjects/image_prediction/im...      4\n",
       "2     /home/kate/PycharmProjects/image_prediction/im...      4\n",
       "3     /home/kate/PycharmProjects/image_prediction/im...      4\n",
       "4     /home/kate/PycharmProjects/image_prediction/im...      4\n",
       "...                                                 ...    ...\n",
       "2995  /home/kate/PycharmProjects/image_prediction/im...      5\n",
       "2996  /home/kate/PycharmProjects/image_prediction/im...      5\n",
       "2997  /home/kate/PycharmProjects/image_prediction/im...      5\n",
       "2998  /home/kate/PycharmProjects/image_prediction/im...      5\n",
       "2999  /home/kate/PycharmProjects/image_prediction/im...      5\n",
       "\n",
       "[3000 rows x 2 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "01775024",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = test_dataset.rename(columns={\"folder_for_file\": \"image\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8687023a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  image  label\n",
       "0     /home/kate/PycharmProjects/image_prediction/im...      4\n",
       "1     /home/kate/PycharmProjects/image_prediction/im...      4\n",
       "2     /home/kate/PycharmProjects/image_prediction/im...      4\n",
       "3     /home/kate/PycharmProjects/image_prediction/im...      4\n",
       "4     /home/kate/PycharmProjects/image_prediction/im...      4\n",
       "...                                                 ...    ...\n",
       "2995  /home/kate/PycharmProjects/image_prediction/im...      5\n",
       "2996  /home/kate/PycharmProjects/image_prediction/im...      5\n",
       "2997  /home/kate/PycharmProjects/image_prediction/im...      5\n",
       "2998  /home/kate/PycharmProjects/image_prediction/im...      5\n",
       "2999  /home/kate/PycharmProjects/image_prediction/im...      5\n",
       "\n",
       "[3000 rows x 2 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d14c4037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 test acc: 0.902\n"
     ]
    }
   ],
   "source": [
    "test_acc = predictor.evaluate(test_dataset)\n",
    "print('Top-1 test acc: %.3f' % test_acc['top1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a6ab2e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b0f8602d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3000):\n",
    "    image_path = test_dataset.iloc[i]['image']\n",
    "    result = predictor.predict(image_path)\n",
    "    a.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f0370599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ddaad3d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(a[2999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ecccd3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(a)):\n",
    "    a[i] = int(a[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "69fd620b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "83a2f7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "47f08b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset['predict'] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2c37ad0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  image  label  predict\n",
       "0     /home/kate/PycharmProjects/image_prediction/im...      4        4\n",
       "1     /home/kate/PycharmProjects/image_prediction/im...      4        4\n",
       "2     /home/kate/PycharmProjects/image_prediction/im...      4        4\n",
       "3     /home/kate/PycharmProjects/image_prediction/im...      4        4\n",
       "4     /home/kate/PycharmProjects/image_prediction/im...      4        4\n",
       "...                                                 ...    ...      ...\n",
       "2995  /home/kate/PycharmProjects/image_prediction/im...      5        5\n",
       "2996  /home/kate/PycharmProjects/image_prediction/im...      5        5\n",
       "2997  /home/kate/PycharmProjects/image_prediction/im...      5        5\n",
       "2998  /home/kate/PycharmProjects/image_prediction/im...      5        5\n",
       "2999  /home/kate/PycharmProjects/image_prediction/im...      5        5\n",
       "\n",
       "[3000 rows x 3 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "59fa0b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6670ece0",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_train_dataset = shuffle(train_dataset, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f40dbe6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9306</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5299</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5725</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8912</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10406</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12172</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13349</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14034 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   image  label\n",
       "9306   /home/kate/PycharmProjects/image_prediction/im...      3\n",
       "5299   /home/kate/PycharmProjects/image_prediction/im...      1\n",
       "5725   /home/kate/PycharmProjects/image_prediction/im...      1\n",
       "8912   /home/kate/PycharmProjects/image_prediction/im...      3\n",
       "10406  /home/kate/PycharmProjects/image_prediction/im...      0\n",
       "...                                                  ...    ...\n",
       "905    /home/kate/PycharmProjects/image_prediction/im...      4\n",
       "5192   /home/kate/PycharmProjects/image_prediction/im...      1\n",
       "12172  /home/kate/PycharmProjects/image_prediction/im...      5\n",
       "235    /home/kate/PycharmProjects/image_prediction/im...      4\n",
       "13349  /home/kate/PycharmProjects/image_prediction/im...      5\n",
       "\n",
       "[14034 rows x 2 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8d712aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ImagePredictor sets accuracy as default eval_metric for classification problems.\n",
      "Converting raw DataFrame to ImageDataset...\n",
      "Detected 6 unique classes: [0, 1, 2, 3, 4, 5]\n",
      "If you feel the `classes` is inaccurate, please construct the dataset explicitly, e.g. train_data = ImageDataset(train_data, classes=[\"foo\", \"bar\"])\n",
      "Randomly split train_data into train[12630]/validation[1404] splits.\n",
      "The number of requested GPUs is greater than the number of available GPUs.Reduce the number to 1\n",
      "Starting HPO experiments\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c647834e57e54e2f8956f0814dfa1501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=============================================================================\n",
      "WARNING: Using MXNet models in ImagePredictor is deprecated as of v0.4.0 and may contain various bugs and issues!\n",
      "In v0.5.0, ImagePredictor will no longer support training MXNet models. Please consider switching to specifying Torch models instead.\n",
      "Users should ensure they update their code that depends on ImagePredictor when upgrading to future AutoGluon releases.\n",
      "For more information, refer to this GitHub issue: https://github.com/awslabs/autogluon/issues/1560\n",
      "=============================================================================\n",
      "\n",
      "modified configs(<old> != <new>): {\n",
      "root.img_cls.model   resnet50_v1 != resnet18_v1b\n",
      "root.train.batch_size 128 != 8\n",
      "root.train.rec_train ~/.mxnet/datasets/imagenet/rec/train.rec != auto\n",
      "root.train.early_stop_max_value 1.0 != inf\n",
      "root.train.early_stop_patience -1 != 10\n",
      "root.train.rec_train_idx ~/.mxnet/datasets/imagenet/rec/train.idx != auto\n",
      "root.train.rec_val   ~/.mxnet/datasets/imagenet/rec/val.rec != auto\n",
      "root.train.data_dir  ~/.mxnet/datasets/imagenet != auto\n",
      "root.train.epochs    10 != 2\n",
      "root.train.num_training_samples 1281167 != -1\n",
      "root.train.early_stop_baseline 0.0 != -inf\n",
      "root.train.lr        0.1 != 0.01\n",
      "root.train.rec_val_idx ~/.mxnet/datasets/imagenet/rec/val.idx != auto\n",
      "root.train.num_workers 4 != 12\n",
      "root.valid.num_workers 4 != 12\n",
      "root.valid.batch_size 128 != 8\n",
      "}\n",
      "Saved config to /home/kate/PycharmProjects/image_prediction/ed126493/.trial_0/config.yaml\n",
      "[18:27:29] ../src/imperative/./imperative_utils.h:93: GPU support is disabled. Compile MXNet with USE_CUDA=1 to enable GPU support.\n",
      "No gpu detected, fallback to cpu. You can ignore this warning if this is intended.\n",
      "Start training from [Epoch 0]\n",
      "Epoch[0] Batch [49]\tSpeed: 23.783318 samples/sec\taccuracy=0.322500\tlr=0.010000\n",
      "Epoch[0] Batch [99]\tSpeed: 22.002150 samples/sec\taccuracy=0.460000\tlr=0.010000\n",
      "Epoch[0] Batch [149]\tSpeed: 21.863516 samples/sec\taccuracy=0.513333\tlr=0.010000\n",
      "Epoch[0] Batch [199]\tSpeed: 23.269351 samples/sec\taccuracy=0.552500\tlr=0.010000\n",
      "Epoch[0] Batch [249]\tSpeed: 22.646777 samples/sec\taccuracy=0.581000\tlr=0.010000\n",
      "Epoch[0] Batch [299]\tSpeed: 22.141287 samples/sec\taccuracy=0.594167\tlr=0.010000\n",
      "Epoch[0] Batch [349]\tSpeed: 23.413786 samples/sec\taccuracy=0.606786\tlr=0.010000\n",
      "Epoch[0] Batch [399]\tSpeed: 20.753998 samples/sec\taccuracy=0.623437\tlr=0.010000\n",
      "Epoch[0] Batch [449]\tSpeed: 20.961989 samples/sec\taccuracy=0.631111\tlr=0.010000\n",
      "Epoch[0] Batch [499]\tSpeed: 21.781982 samples/sec\taccuracy=0.640000\tlr=0.010000\n",
      "Epoch[0] Batch [549]\tSpeed: 22.895640 samples/sec\taccuracy=0.647500\tlr=0.010000\n",
      "Epoch[0] Batch [599]\tSpeed: 24.044776 samples/sec\taccuracy=0.655000\tlr=0.010000\n",
      "Epoch[0] Batch [649]\tSpeed: 23.899848 samples/sec\taccuracy=0.660769\tlr=0.010000\n",
      "Epoch[0] Batch [699]\tSpeed: 24.844323 samples/sec\taccuracy=0.668571\tlr=0.010000\n",
      "Epoch[0] Batch [749]\tSpeed: 21.942533 samples/sec\taccuracy=0.673667\tlr=0.010000\n",
      "Epoch[0] Batch [799]\tSpeed: 22.698496 samples/sec\taccuracy=0.679688\tlr=0.010000\n",
      "Epoch[0] Batch [849]\tSpeed: 22.408057 samples/sec\taccuracy=0.684706\tlr=0.010000\n",
      "Epoch[0] Batch [899]\tSpeed: 23.824543 samples/sec\taccuracy=0.689722\tlr=0.010000\n",
      "Epoch[0] Batch [949]\tSpeed: 23.573720 samples/sec\taccuracy=0.690921\tlr=0.010000\n",
      "Epoch[0] Batch [999]\tSpeed: 20.733278 samples/sec\taccuracy=0.692500\tlr=0.010000\n",
      "Epoch[0] Batch [1049]\tSpeed: 20.873138 samples/sec\taccuracy=0.696905\tlr=0.010000\n",
      "Epoch[0] Batch [1099]\tSpeed: 24.643967 samples/sec\taccuracy=0.701136\tlr=0.010000\n",
      "Epoch[0] Batch [1149]\tSpeed: 23.774545 samples/sec\taccuracy=0.704239\tlr=0.010000\n",
      "Epoch[0] Batch [1199]\tSpeed: 22.340898 samples/sec\taccuracy=0.707083\tlr=0.010000\n",
      "Epoch[0] Batch [1249]\tSpeed: 22.300973 samples/sec\taccuracy=0.709800\tlr=0.010000\n",
      "Epoch[0] Batch [1299]\tSpeed: 23.809957 samples/sec\taccuracy=0.713365\tlr=0.010000\n",
      "Epoch[0] Batch [1349]\tSpeed: 21.795185 samples/sec\taccuracy=0.716852\tlr=0.010000\n",
      "Epoch[0] Batch [1399]\tSpeed: 21.946692 samples/sec\taccuracy=0.718661\tlr=0.010000\n",
      "Epoch[0] Batch [1449]\tSpeed: 23.369696 samples/sec\taccuracy=0.720862\tlr=0.010000\n",
      "Epoch[0] Batch [1499]\tSpeed: 21.790278 samples/sec\taccuracy=0.723667\tlr=0.010000\n",
      "Epoch[0] Batch [1549]\tSpeed: 21.788202 samples/sec\taccuracy=0.724758\tlr=0.010000\n",
      "[Epoch 0] training: accuracy=0.725998\n",
      "[Epoch 0] speed: 22 samples/sec\ttime cost: 558.380372\n",
      "[Epoch 0] validation: top1=0.879630 top5=0.998575\n",
      "[Epoch 0] Current best top-1: 0.879630 vs previous -inf, saved to /home/kate/PycharmProjects/image_prediction/ed126493/.trial_0/best_checkpoint.pkl\n",
      "Epoch[1] Batch [49]\tSpeed: 19.184160 samples/sec\taccuracy=0.760000\tlr=0.010000\n",
      "`time_limit=599.9782106876373` reached, exit early...\n",
      "Applying the state from the best checkpoint...\n",
      "[18:37:37] ../src/imperative/./imperative_utils.h:93: GPU support is disabled. Compile MXNet with USE_CUDA=1 to enable GPU support.\n",
      "\tStopping HPO to satisfy time limit...\n",
      "=============================================================================\n",
      "WARNING: Using MXNet models in ImagePredictor is deprecated as of v0.4.0 and may contain various bugs and issues!\n",
      "In v0.5.0, ImagePredictor will no longer support training MXNet models. Please consider switching to specifying Torch models instead.\n",
      "Users should ensure they update their code that depends on ImagePredictor when upgrading to future AutoGluon releases.\n",
      "For more information, refer to this GitHub issue: https://github.com/awslabs/autogluon/issues/1560\n",
      "=============================================================================\n",
      "\n",
      "[18:37:38] ../src/imperative/./imperative_utils.h:93: GPU support is disabled. Compile MXNet with USE_CUDA=1 to enable GPU support.\n",
      "Saving Training Curve in /home/kate/PycharmProjects/image_prediction/ed126493/plot_training_curves.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finished, total runtime is 609.71 s\n",
      "{ 'best_config': { 'estimator': <class 'gluoncv.auto.estimators.image_classification.image_classification.ImageClassificationEstimator'>,\n",
      "                   'gpus': [0],\n",
      "                   'img_cls': { 'batch_norm': False,\n",
      "                                'last_gamma': False,\n",
      "                                'model': 'resnet18_v1b',\n",
      "                                'use_gn': False,\n",
      "                                'use_pretrained': True,\n",
      "                                'use_se': False},\n",
      "                   'train': { 'batch_size': 8,\n",
      "                              'crop_ratio': 0.875,\n",
      "                              'data_dir': 'auto',\n",
      "                              'dtype': 'float32',\n",
      "                              'early_stop_baseline': -inf,\n",
      "                              'early_stop_max_value': inf,\n",
      "                              'early_stop_min_delta': 0.001,\n",
      "                              'early_stop_patience': 10,\n",
      "                              'epochs': 2,\n",
      "                              'hard_weight': 0.5,\n",
      "                              'input_size': 224,\n",
      "                              'label_smoothing': False,\n",
      "                              'log_interval': 50,\n",
      "                              'lr': 0.01,\n",
      "                              'lr_decay': 0.1,\n",
      "                              'lr_decay_epoch': '40, 60',\n",
      "                              'lr_decay_period': 0,\n",
      "                              'lr_mode': 'step',\n",
      "                              'mixup': False,\n",
      "                              'mixup_alpha': 0.2,\n",
      "                              'mixup_off_epoch': 0,\n",
      "                              'mode': '',\n",
      "                              'momentum': 0.9,\n",
      "                              'no_wd': False,\n",
      "                              'num_training_samples': -1,\n",
      "                              'num_workers': 12,\n",
      "                              'output_lr_mult': 0.1,\n",
      "                              'pretrained_base': True,\n",
      "                              'rec_train': 'auto',\n",
      "                              'rec_train_idx': 'auto',\n",
      "                              'rec_val': 'auto',\n",
      "                              'rec_val_idx': 'auto',\n",
      "                              'resume_epoch': 0,\n",
      "                              'start_epoch': 0,\n",
      "                              'teacher': None,\n",
      "                              'temperature': 20,\n",
      "                              'transfer_lr_mult': 0.01,\n",
      "                              'use_rec': False,\n",
      "                              'warmup_epochs': 0,\n",
      "                              'warmup_lr': 0.0,\n",
      "                              'wd': 0.0001},\n",
      "                   'valid': {'batch_size': 8, 'num_workers': 12}},\n",
      "  'total_time': 609.5169146060944,\n",
      "  'train_acc': 0.76,\n",
      "  'valid_acc': 0.8796296296296297}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 val acc: 0.880\n"
     ]
    }
   ],
   "source": [
    "hyperparameters={'model': model, 'batch_size': batch_size, 'lr': lr, 'epochs': 2}\n",
    "predictor = ImagePredictor()\n",
    "predictor.fit(shuffled_train_dataset, time_limit=60*10, hyperparameters=hyperparameters,\n",
    "              hyperparameter_tune_kwargs={'num_trials': 2})\n",
    "print('Top-1 val acc: %.3f' % predictor.fit_summary()['valid_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "78186932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 test acc: 0.887\n"
     ]
    }
   ],
   "source": [
    "test_acc = predictor.evaluate(test_dataset)\n",
    "print('Top-1 test acc: %.3f' % test_acc['top1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b8ccb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
