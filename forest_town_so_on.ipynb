{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b1337ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kate/.local/lib/python3.8/site-packages/gluoncv/__init__.py:40: UserWarning: Both `mxnet==1.9.1` and `torch==1.10.2+cu102` are installed. You might encounter increased GPU memory footprint if both framework are used at the same time.\n",
      "  warnings.warn(f'Both `mxnet=={mx.__version__}` and `torch=={torch.__version__}` are installed. '\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from mxnet import autograd, gluon\n",
    "import gluoncv as gcv\n",
    "from gluoncv.utils import download, viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acc24903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe3fe4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/home/kate/PycharmProjects/image_prediction/images/'\n",
    "#test_dir = '../input/intel-image-classification/seg_test/seg_test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94d43c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = os.listdir(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77f3f891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['seg_train', 'seg_test', 'seg_pred']\n"
     ]
    }
   ],
   "source": [
    "print(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b54adae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/kate/PycharmProjects/image_prediction/images/seg_train/'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path+folders[0]+'/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8a61dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folders = os.listdir(os.path.join(base_path,folders[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6e21ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_folders: ['sea', 'glacier', 'forest', 'mountain', 'buildings', 'street']\n"
     ]
    }
   ],
   "source": [
    "print(f'train_folders: {train_folders}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c29f115a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Train Data Distribution-----\n",
      "Folder Name : No. of Images\n",
      "sea         : 2274\n",
      "glacier     : 2404\n",
      "forest      : 2271\n",
      "mountain    : 2512\n",
      "buildings   : 2191\n",
      "street      : 2382\n"
     ]
    }
   ],
   "source": [
    "print('----Train Data Distribution-----')\n",
    "print(f'Folder Name : No. of Images')\n",
    "for folder in train_folders:\n",
    "    print(f'{folder:11} : {len(os.listdir(os.path.join(base_path,folders[0],folder)))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7ed9c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_folders: ['sea', 'glacier', 'forest', 'mountain', 'buildings', 'street']\n"
     ]
    }
   ],
   "source": [
    "val_folders = os.listdir(os.path.join(base_path,folders[1]))\n",
    "print(f'val_folders: {val_folders}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47f9d010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Val Data Distribution-----\n",
      "Folder Name : No. of Images\n",
      "sea         : 510\n",
      "glacier     : 553\n",
      "forest      : 474\n",
      "mountain    : 525\n",
      "buildings   : 437\n",
      "street      : 501\n"
     ]
    }
   ],
   "source": [
    "print('----Val Data Distribution-----')\n",
    "print(f'Folder Name : No. of Images')\n",
    "for folder in val_folders:\n",
    "    print(f'{folder:11} : {len(os.listdir(os.path.join(base_path,folders[1],folder)))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3d7737f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_images: 7301\n",
      "First ten Images\n",
      "['21326.jpg', '5803.jpg', '12901.jpg', '7943.jpg', '677.jpg', '22049.jpg', '12033.jpg', '10434.jpg', '5229.jpg', '19065.jpg']\n"
     ]
    }
   ],
   "source": [
    "test_images = os.listdir(os.path.join(base_path,folders[2]))\n",
    "print(f'test_images: {len(test_images)}')\n",
    "print('First ten Images')\n",
    "print(test_images[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64209c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3280f23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(columns =['Names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56cdead5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Names]\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9cd32c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_folders)):\n",
    "    folder = train_folders[i]\n",
    "    a = os.listdir(os.path.join(base_path,folders[0],folder))\n",
    "    df = pd.DataFrame(a, columns =['Names'])\n",
    "    df = df.assign(Folder_Name = folder)\n",
    "    data = pd.concat([df_train, df], ignore_index=True)\n",
    "    df_train = data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "959aaf90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "      <th>Folder_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14541.jpg</td>\n",
       "      <td>sea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1543.jpg</td>\n",
       "      <td>sea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19360.jpg</td>\n",
       "      <td>sea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11382.jpg</td>\n",
       "      <td>sea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10177.jpg</td>\n",
       "      <td>sea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14029</th>\n",
       "      <td>11113.jpg</td>\n",
       "      <td>street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14030</th>\n",
       "      <td>1618.jpg</td>\n",
       "      <td>street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14031</th>\n",
       "      <td>14839.jpg</td>\n",
       "      <td>street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14032</th>\n",
       "      <td>3911.jpg</td>\n",
       "      <td>street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14033</th>\n",
       "      <td>1091.jpg</td>\n",
       "      <td>street</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14034 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Names Folder_Name\n",
       "0      14541.jpg         sea\n",
       "1       1543.jpg         sea\n",
       "2      19360.jpg         sea\n",
       "3      11382.jpg         sea\n",
       "4      10177.jpg         sea\n",
       "...          ...         ...\n",
       "14029  11113.jpg      street\n",
       "14030   1618.jpg      street\n",
       "14031  14839.jpg      street\n",
       "14032   3911.jpg      street\n",
       "14033   1091.jpg      street\n",
       "\n",
       "[14034 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9fda991c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sea', 'glacier', 'forest', 'mountain', 'buildings', 'street'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Folder_Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b76e1d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        14541.jpg\n",
       "1         1543.jpg\n",
       "2        19360.jpg\n",
       "3        11382.jpg\n",
       "4        10177.jpg\n",
       "           ...    \n",
       "14029    11113.jpg\n",
       "14030     1618.jpg\n",
       "14031    14839.jpg\n",
       "14032     3911.jpg\n",
       "14033     1091.jpg\n",
       "Name: Names, Length: 14034, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b929b19a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['seg_train', 'seg_test', 'seg_pred']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23e9284d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        /home/kate/PycharmProjects/image_prediction/im...\n",
       "1        /home/kate/PycharmProjects/image_prediction/im...\n",
       "2        /home/kate/PycharmProjects/image_prediction/im...\n",
       "3        /home/kate/PycharmProjects/image_prediction/im...\n",
       "4        /home/kate/PycharmProjects/image_prediction/im...\n",
       "                               ...                        \n",
       "14029    /home/kate/PycharmProjects/image_prediction/im...\n",
       "14030    /home/kate/PycharmProjects/image_prediction/im...\n",
       "14031    /home/kate/PycharmProjects/image_prediction/im...\n",
       "14032    /home/kate/PycharmProjects/image_prediction/im...\n",
       "14033    /home/kate/PycharmProjects/image_prediction/im...\n",
       "Name: Folder_Name, Length: 14034, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path+folders[0]+'/'+df_train['Folder_Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d127faae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['folder_for_file'] = base_path+folders[0]+'/'+ df_train['Folder_Name']+'/'+df_train['Names']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14112795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "      <th>Folder_Name</th>\n",
       "      <th>folder_for_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14541.jpg</td>\n",
       "      <td>sea</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1543.jpg</td>\n",
       "      <td>sea</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19360.jpg</td>\n",
       "      <td>sea</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11382.jpg</td>\n",
       "      <td>sea</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10177.jpg</td>\n",
       "      <td>sea</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14029</th>\n",
       "      <td>11113.jpg</td>\n",
       "      <td>street</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14030</th>\n",
       "      <td>1618.jpg</td>\n",
       "      <td>street</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14031</th>\n",
       "      <td>14839.jpg</td>\n",
       "      <td>street</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14032</th>\n",
       "      <td>3911.jpg</td>\n",
       "      <td>street</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14033</th>\n",
       "      <td>1091.jpg</td>\n",
       "      <td>street</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14034 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Names Folder_Name  \\\n",
       "0      14541.jpg         sea   \n",
       "1       1543.jpg         sea   \n",
       "2      19360.jpg         sea   \n",
       "3      11382.jpg         sea   \n",
       "4      10177.jpg         sea   \n",
       "...          ...         ...   \n",
       "14029  11113.jpg      street   \n",
       "14030   1618.jpg      street   \n",
       "14031  14839.jpg      street   \n",
       "14032   3911.jpg      street   \n",
       "14033   1091.jpg      street   \n",
       "\n",
       "                                         folder_for_file  \n",
       "0      /home/kate/PycharmProjects/image_prediction/im...  \n",
       "1      /home/kate/PycharmProjects/image_prediction/im...  \n",
       "2      /home/kate/PycharmProjects/image_prediction/im...  \n",
       "3      /home/kate/PycharmProjects/image_prediction/im...  \n",
       "4      /home/kate/PycharmProjects/image_prediction/im...  \n",
       "...                                                  ...  \n",
       "14029  /home/kate/PycharmProjects/image_prediction/im...  \n",
       "14030  /home/kate/PycharmProjects/image_prediction/im...  \n",
       "14031  /home/kate/PycharmProjects/image_prediction/im...  \n",
       "14032  /home/kate/PycharmProjects/image_prediction/im...  \n",
       "14033  /home/kate/PycharmProjects/image_prediction/im...  \n",
       "\n",
       "[14034 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec018476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_rating(folder):\n",
    "    if folder == 'glacier':\n",
    "        return (2)\n",
    "    elif folder == 'sea':\n",
    "        return (4)\n",
    "    elif folder == 'buildings':\n",
    "        return (0)\n",
    "    elif folder == 'forest':\n",
    "        return (1)\n",
    "    elif folder == 'street':\n",
    "        return (5)\n",
    "    \n",
    "    elif folder == 'mountain':\n",
    "        return (3)\n",
    "        \n",
    "df_train['label'] = df_train.Folder_Name.apply(lambda x: custom_rating(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4621aee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "      <th>Folder_Name</th>\n",
       "      <th>folder_for_file</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14541.jpg</td>\n",
       "      <td>sea</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1543.jpg</td>\n",
       "      <td>sea</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19360.jpg</td>\n",
       "      <td>sea</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11382.jpg</td>\n",
       "      <td>sea</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10177.jpg</td>\n",
       "      <td>sea</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14029</th>\n",
       "      <td>11113.jpg</td>\n",
       "      <td>street</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14030</th>\n",
       "      <td>1618.jpg</td>\n",
       "      <td>street</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14031</th>\n",
       "      <td>14839.jpg</td>\n",
       "      <td>street</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14032</th>\n",
       "      <td>3911.jpg</td>\n",
       "      <td>street</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14033</th>\n",
       "      <td>1091.jpg</td>\n",
       "      <td>street</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14034 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Names Folder_Name  \\\n",
       "0      14541.jpg         sea   \n",
       "1       1543.jpg         sea   \n",
       "2      19360.jpg         sea   \n",
       "3      11382.jpg         sea   \n",
       "4      10177.jpg         sea   \n",
       "...          ...         ...   \n",
       "14029  11113.jpg      street   \n",
       "14030   1618.jpg      street   \n",
       "14031  14839.jpg      street   \n",
       "14032   3911.jpg      street   \n",
       "14033   1091.jpg      street   \n",
       "\n",
       "                                         folder_for_file  label  \n",
       "0      /home/kate/PycharmProjects/image_prediction/im...      4  \n",
       "1      /home/kate/PycharmProjects/image_prediction/im...      4  \n",
       "2      /home/kate/PycharmProjects/image_prediction/im...      4  \n",
       "3      /home/kate/PycharmProjects/image_prediction/im...      4  \n",
       "4      /home/kate/PycharmProjects/image_prediction/im...      4  \n",
       "...                                                  ...    ...  \n",
       "14029  /home/kate/PycharmProjects/image_prediction/im...      5  \n",
       "14030  /home/kate/PycharmProjects/image_prediction/im...      5  \n",
       "14031  /home/kate/PycharmProjects/image_prediction/im...      5  \n",
       "14032  /home/kate/PycharmProjects/image_prediction/im...      5  \n",
       "14033  /home/kate/PycharmProjects/image_prediction/im...      5  \n",
       "\n",
       "[14034 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "34b239c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af65bc49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/kate/PycharmProjects/image_prediction/images/seg_train/sea/14541.jpg'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.folder_for_file[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51b13355",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 12:03:03.156303: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-14 12:03:03.156356: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import autogluon.core as ag\n",
    "from autogluon.vision import ImageDataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81394e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2f219f",
   "metadata": {},
   "source": [
    "def get_images(directory):\n",
    "    Images = []\n",
    "    Labels = []\n",
    "    label = 0\n",
    "    \n",
    "    for labels in os.listdir(directory):\n",
    "        if labels == 'glacier':\n",
    "            label = 2\n",
    "        elif labels == 'sea':\n",
    "            label = 4\n",
    "        elif labels == 'buildings':\n",
    "            label = 0\n",
    "        elif labels == 'forest':\n",
    "            label = 1\n",
    "        elif labels == 'street':\n",
    "            label = 5\n",
    "        elif labels == 'mountain':\n",
    "            label = 3\n",
    "        \n",
    "        for image_file in os.listdir(directory+labels):\n",
    "            image = cv2.imread(directory+labels+r'/'+image_file)\n",
    "            image = cv2.resize(image,(150,150))\n",
    "            Images.append(image)\n",
    "            Labels.append(label)\n",
    "    \n",
    "    return shuffle(Images,Labels,random_state=817328462)\n",
    "\n",
    "def get_classlabel(class_code):\n",
    "    labels = {2:'glacier', 4:'sea', 0:'buildings', 1:'forest', 5:'street', 3:'mountain'}\n",
    "    \n",
    "    return labels[class_code]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413887b4",
   "metadata": {},
   "source": [
    "Images, Labels = get_images('/home/kate/PycharmProjects/image_prediction/images/seg_train/')\n",
    "\n",
    "Images = np.array(Images)\n",
    "Labels = np.array(Labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6813541c",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(16,9))\n",
    "for i in range(0, 9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(Images[i])\n",
    "    plt.title(get_classlabel(Labels[i]))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "015ab012",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogluon.core as ag\n",
    "from autogluon.vision import ImagePredictor, ImageDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9164dfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = df_train[['folder_for_file','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f21da225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder_for_file</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14029</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14030</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14031</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14032</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14033</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14034 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         folder_for_file  label\n",
       "0      /home/kate/PycharmProjects/image_prediction/im...      4\n",
       "1      /home/kate/PycharmProjects/image_prediction/im...      4\n",
       "2      /home/kate/PycharmProjects/image_prediction/im...      4\n",
       "3      /home/kate/PycharmProjects/image_prediction/im...      4\n",
       "4      /home/kate/PycharmProjects/image_prediction/im...      4\n",
       "...                                                  ...    ...\n",
       "14029  /home/kate/PycharmProjects/image_prediction/im...      5\n",
       "14030  /home/kate/PycharmProjects/image_prediction/im...      5\n",
       "14031  /home/kate/PycharmProjects/image_prediction/im...      5\n",
       "14032  /home/kate/PycharmProjects/image_prediction/im...      5\n",
       "14033  /home/kate/PycharmProjects/image_prediction/im...      5\n",
       "\n",
       "[14034 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c0839b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder_for_file</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14029</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14030</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14031</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14032</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14033</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14034 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         folder_for_file  label\n",
       "0      /home/kate/PycharmProjects/image_prediction/im...      4\n",
       "1      /home/kate/PycharmProjects/image_prediction/im...      4\n",
       "2      /home/kate/PycharmProjects/image_prediction/im...      4\n",
       "3      /home/kate/PycharmProjects/image_prediction/im...      4\n",
       "4      /home/kate/PycharmProjects/image_prediction/im...      4\n",
       "...                                                  ...    ...\n",
       "14029  /home/kate/PycharmProjects/image_prediction/im...      5\n",
       "14030  /home/kate/PycharmProjects/image_prediction/im...      5\n",
       "14031  /home/kate/PycharmProjects/image_prediction/im...      5\n",
       "14032  /home/kate/PycharmProjects/image_prediction/im...      5\n",
       "14033  /home/kate/PycharmProjects/image_prediction/im...      5\n",
       "\n",
       "[14034 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5b67faa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.rename(columns={\"folder_for_file\": \"image\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "29af2877",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = ImagePredictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e1b92c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`time_limit=auto` set to `time_limit=7200`.\n",
      "Converting raw DataFrame to ImageDataset...\n",
      "Detected 6 unique classes: [0, 1, 2, 3, 4, 5]\n",
      "If you feel the `classes` is inaccurate, please construct the dataset explicitly, e.g. train_data = ImageDataset(train_data, classes=[\"foo\", \"bar\"])\n",
      "Randomly split train_data into train[12630]/validation[1404] splits.\n",
      "The number of requested GPUs is greater than the number of available GPUs.Reduce the number to 1\n",
      "Starting fit without HPO\n",
      "modified configs(<old> != <new>): {\n",
      "root.misc.seed       42 != 709\n",
      "root.misc.num_workers 4 != 12\n",
      "root.train.epochs    200 != 2\n",
      "root.train.early_stop_max_value 1.0 != inf\n",
      "root.train.batch_size 32 != 16\n",
      "root.train.early_stop_baseline 0.0 != -inf\n",
      "root.train.early_stop_patience -1 != 10\n",
      "root.img_cls.model   resnet101 != resnet50\n",
      "}\n",
      "Saved config to /home/kate/PycharmProjects/image_prediction/950a027b/.trial_0/config.yaml\n",
      "Model resnet50 created, param count:                                         23520326\n",
      "AMP not enabled. Training in float32.\n",
      "Disable EMA as it is not supported for now.\n",
      "Start training from [Epoch 0]\n",
      "Finished, total runtime is 18.23 s\n",
      "{ 'best_config': { 'batch_size': 16,\n",
      "                   'dist_ip_addrs': None,\n",
      "                   'early_stop_baseline': -inf,\n",
      "                   'early_stop_max_value': inf,\n",
      "                   'early_stop_patience': 10,\n",
      "                   'epochs': 2,\n",
      "                   'final_fit': False,\n",
      "                   'gpus': [0],\n",
      "                   'lr': 0.01,\n",
      "                   'model': 'resnet50',\n",
      "                   'ngpus_per_trial': 8,\n",
      "                   'nthreads_per_trial': 128,\n",
      "                   'num_workers': 12,\n",
      "                   'searcher': 'random',\n",
      "                   'seed': 709,\n",
      "                   'time_limits': 7200},\n",
      "  'total_time': 18.153749227523804,\n",
      "  'train_acc': -1,\n",
      "  'valid_acc': -1}\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Unexpected error happened during fit: { 'args': \"{'img_cls': {'model': 'resnet50', 'pretrained': True, \"\n          \"'global_pool_type': None}, 'data': {'img_size': None, 'input_size': \"\n          \"None, 'crop_pct': 0.99, 'mean': None, 'std': None, 'interpolation': \"\n          \"'', 'validation_batch_size_multiplier': 1}, 'optimizer': {'opt': \"\n          \"'sgd', 'opt_eps': None, 'opt_betas': None, 'momentum': 0.9, \"\n          \"'weight_decay': 0.0001, 'clip_grad': None, 'clip_mode': 'norm'}, \"\n          \"'train': {'batch_size': 16, 'sched': 'step', 'lr': 0.01, \"\n          \"'lr_noise': None, 'lr_noise_pct': 0.67, 'lr_noise_std': 1.0, \"\n          \"'lr_cycle_mul': 1.0, 'lr_cycle_limit': 1, 'transfer_lr_mult': 0.01, \"\n          \"'output_lr_mult': 0.1, 'warmup_lr': 0.0001, 'min_lr': 1e-05, \"\n          \"'epochs': 2, 'start_epoch': 0, 'decay_epochs': 30, 'warmup_epochs': \"\n          \"3, 'cooldown_epochs': 10, 'patience_epochs': 10, 'decay_rate': 0.1, \"\n          \"'bn_momentum': None, 'bn_eps': None, 'sync_bn': False, \"\n          \"'early_stop_patience': 10, 'early_stop_min_delta': 0.001, \"\n          \"'early_stop_baseline': -inf, 'early_stop_max_value': inf}, \"\n          \"'augmentation': {'no_aug': False, 'scale': (0.08, 1.0), 'ratio': \"\n          \"(0.75, 1.3333333333333333), 'hflip': 0.5, 'vflip': 0.0, \"\n          \"'color_jitter': 0.4, 'auto_augment': None, 'mixup': 0.0, 'cutmix': \"\n          \"0.0, 'cutmix_minmax': None, 'mixup_prob': 1.0, 'mixup_switch_prob': \"\n          \"0.5, 'mixup_mode': 'batch', 'mixup_off_epoch': 0, 'smoothing': 0.1, \"\n          \"'train_interpolation': 'random', 'drop': 0.0, 'drop_path': None, \"\n          \"'drop_block': None}, 'model_ema': {'model_ema': True, \"\n          \"'model_ema_force_cpu': False, 'model_ema_decay': 0.9998}, 'misc': \"\n          \"{'seed': 709, 'log_interval': 50, 'num_workers': 12, 'save_images': \"\n          \"False, 'amp': False, 'apex_amp': False, 'native_amp': False, \"\n          \"'pin_mem': False, 'prefetcher': False, 'eval_metric': 'top1', \"\n          \"'tta': 0, 'use_multi_epochs_loader': False, 'torchscript': False}, \"\n          \"'gpus': [0]}\",\n  'time': 18.153749227523804,\n  'traceback': 'Traceback (most recent call last):\\n'\n               '  File '\n               '\"/home/kate/.local/lib/python3.8/site-packages/autogluon/vision/_gluoncv/image_classification.py\", '\n               'line 191, in _train_image_classification\\n'\n               '    result = estimator.fit(train_data=train_data, '\n               'val_data=val_data, time_limit=wall_clock_tick-tic)\\n'\n               '  File '\n               '\"/home/kate/.local/lib/python3.8/site-packages/gluoncv/auto/estimators/base_estimator.py\", '\n               'line 175, in fit\\n'\n               '    ret = self._fit(train_data, val_data, '\n               'time_limit=time_limit) if not resume else \\\\\\n'\n               '  File '\n               '\"/home/kate/.local/lib/python3.8/site-packages/gluoncv/auto/estimators/torch_image_classification/torch_image_classification.py\", '\n               'line 123, in _fit\\n'\n               '    return self._resume_fit(train_data, val_data, '\n               'time_limit=time_limit)\\n'\n               '  File '\n               '\"/home/kate/.local/lib/python3.8/site-packages/gluoncv/auto/estimators/torch_image_classification/torch_image_classification.py\", '\n               'line 201, in _resume_fit\\n'\n               '    return self._train_loop(train_loader, val_loader, '\n               'time_limit=time_limit)\\n'\n               '  File '\n               '\"/home/kate/.local/lib/python3.8/site-packages/gluoncv/auto/estimators/torch_image_classification/torch_image_classification.py\", '\n               'line 239, in _train_loop\\n'\n               '    train_metrics = self.train_one_epoch(\\n'\n               '  File '\n               '\"/home/kate/.local/lib/python3.8/site-packages/gluoncv/auto/estimators/torch_image_classification/torch_image_classification.py\", '\n               'line 337, in train_one_epoch\\n'\n               '    output = net(input)\\n'\n               '  File '\n               '\"/home/kate/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", '\n               'line 1102, in _call_impl\\n'\n               '    return forward_call(*input, **kwargs)\\n'\n               '  File '\n               '\"/home/kate/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", '\n               'line 166, in forward\\n'\n               '    return self.module(*inputs[0], **kwargs[0])\\n'\n               '  File '\n               '\"/home/kate/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", '\n               'line 1102, in _call_impl\\n'\n               '    return forward_call(*input, **kwargs)\\n'\n               '  File '\n               '\"/home/kate/.local/lib/python3.8/site-packages/timm/models/resnet.py\", '\n               'line 685, in forward\\n'\n               '    x = self.forward_features(x)\\n'\n               '  File '\n               '\"/home/kate/.local/lib/python3.8/site-packages/timm/models/resnet.py\", '\n               'line 679, in forward_features\\n'\n               '    x = self.layer2(x)\\n'\n               '  File '\n               '\"/home/kate/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", '\n               'line 1102, in _call_impl\\n'\n               '    return forward_call(*input, **kwargs)\\n'\n               '  File '\n               '\"/home/kate/.local/lib/python3.8/site-packages/torch/nn/modules/container.py\", '\n               'line 141, in forward\\n'\n               '    input = module(input)\\n'\n               '  File '\n               '\"/home/kate/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", '\n               'line 1102, in _call_impl\\n'\n               '    return forward_call(*input, **kwargs)\\n'\n               '  File '\n               '\"/home/kate/.local/lib/python3.8/site-packages/timm/models/resnet.py\", '\n               'line 410, in forward\\n'\n               '    x = self.bn2(x)\\n'\n               '  File '\n               '\"/home/kate/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", '\n               'line 1102, in _call_impl\\n'\n               '    return forward_call(*input, **kwargs)\\n'\n               '  File '\n               '\"/home/kate/.local/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py\", '\n               'line 168, in forward\\n'\n               '    return F.batch_norm(\\n'\n               '  File '\n               '\"/home/kate/.local/lib/python3.8/site-packages/torch/nn/functional.py\", '\n               'line 2282, in batch_norm\\n'\n               '    return torch.batch_norm(\\n'\n               'RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB '\n               '(GPU 0; 1.95 GiB total capacity; 789.73 MiB already allocated; '\n               '9.88 MiB free; 822.00 MiB reserved in total by PyTorch) If '\n               'reserved memory is >> allocated memory try setting '\n               'max_split_size_mb to avoid fragmentation.  See documentation '\n               'for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n',\n  'train_acc': -1,\n  'valid_acc': -1}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/autogluon/vision/configs/presets_configs.py:18\u001b[0m, in \u001b[0;36munpack.<locals>._unpack_inner.<locals>._call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     17\u001b[0m     gargs, gkwargs \u001b[38;5;241m=\u001b[39m set_presets(preset_name, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/autogluon/vision/predictor/predictor.py:419\u001b[0m, in \u001b[0;36mImagePredictor.fit\u001b[0;34m(self, train_data, tuning_data, time_limit, presets, hyperparameters, **kwargs)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_classes \u001b[38;5;241m=\u001b[39m train_data\u001b[38;5;241m.\u001b[39mclasses\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings(record\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m w:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;66;03m# TODO: MXNetErrorCatcher was removed because it didn't return traceback\u001b[39;00m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;66;03m#  Re-add once it returns full traceback regardless of which exception was caught\u001b[39;00m\n\u001b[0;32m--> 419\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_classifier \u001b[38;5;241m=\u001b[39m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtuning_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mholdout_frac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_classifier\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39msetLevel(log_level)\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_classifier\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39mpropagate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/autogluon/vision/_gluoncv/image_classification.py:421\u001b[0m, in \u001b[0;36mImageClassification.fit\u001b[0;34m(self, train_data, val_data, train_size, random_state, time_limit)\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraceback\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    420\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnable to fit a usable model given `time_limit=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime_limit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 421\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnexpected error happened during fit: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpprint\u001b[38;5;241m.\u001b[39mpformat(results, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_checkpoint\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m    423\u001b[0m     estimator \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mloads(results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_checkpoint\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unexpected error happened during fit: { 'args': \"{'img_cls': {'model': 'resnet50', 'pretrained': True, \"\n          \"'global_pool_type': None}, 'data': {'img_size': None, 'input_size': \"\n          \"None, 'crop_pct': 0.99, 'mean': None, 'std': None, 'interpolation': \"\n          \"'', 'validation_batch_size_multiplier': 1}, 'optimizer': {'opt': \"\n          \"'sgd', 'opt_eps': None, 'opt_betas': None, 'momentum': 0.9, \"\n          \"'weight_decay': 0.0001, 'clip_grad': None, 'clip_mode': 'norm'}, \"\n          \"'train': {'batch_size': 16, 'sched': 'step', 'lr': 0.01, \"\n          \"'lr_noise': None, 'lr_noise_pct': 0.67, 'lr_noise_std': 1.0, \"\n          \"'lr_cycle_mul': 1.0, 'lr_cycle_limit': 1, 'transfer_lr_mult': 0.01, \"\n          \"'output_lr_mult': 0.1, 'warmup_lr': 0.0001, 'min_lr': 1e-05, \"\n          \"'epochs': 2, 'start_epoch': 0, 'decay_epochs': 30, 'warmup_epochs': \"\n          \"3, 'cooldown_epochs': 10, 'patience_epochs': 10, 'decay_rate': 0.1, \"\n          \"'bn_momentum': None, 'bn_eps': None, 'sync_bn': False, \"\n          \"'early_stop_patience': 10, 'early_stop_min_delta': 0.001, \"\n          \"'early_stop_baseline': -inf, 'early_stop_max_value': inf}, \"\n          \"'augmentation': {'no_aug': False, 'scale': (0.08, 1.0), 'ratio': \"\n          \"(0.75, 1.3333333333333333), 'hflip': 0.5, 'vflip': 0.0, \"\n          \"'color_jitter': 0.4, 'auto_augment': None, 'mixup': 0.0, 'cutmix': \"\n          \"0.0, 'cutmix_minmax': None, 'mixup_prob': 1.0, 'mixup_switch_prob': \"\n          \"0.5, 'mixup_mode': 'batch', 'mixup_off_epoch': 0, 'smoothing': 0.1, \"\n          \"'train_interpolation': 'random', 'drop': 0.0, 'drop_path': None, \"\n          \"'drop_block': None}, 'model_ema': {'model_ema': True, \"\n          \"'model_ema_force_cpu': False, 'model_ema_decay': 0.9998}, 'misc': \"\n          \"{'seed': 709, 'log_interval': 50, 'num_workers': 12, 'save_images': \"\n          \"False, 'amp': False, 'apex_amp': False, 'native_amp': False, \"\n          \"'pin_mem': False, 'prefetcher': False, 'eval_metric': 'top1', \"\n          \"'tta': 0, 'use_multi_epochs_loader': False, 'torchscript': False}, \"\n          \"'gpus': [0]}\",\n  'time': 18.153749227523804,\n  'traceback': 'Traceback (most recent call last):\\n'\n               '  File '\n               '\"/home/kate/.local/lib/python3.8/site-packages/autogluon/vision/_gluoncv/image_classification.py\", '\n               'line 191, in _train_image_classification\\n'\n               '    result = estimator.fit(train_data=train_data, '\n               'val_data=val_data, time_limit=wall_clock_tick-tic)\\n'\n               '  File '\n               '\"/home/kate/.local/lib/python3.8/site-packages/gluoncv/auto/estimators/base_estimator.py\", '\n               'line 175, in fit\\n'\n               '    ret = self._fit(train_data, val_data, '\n               'time_limit=time_limit) if not resume else \\\\\\n'\n               '  File '\n               '\"/home/kate/.local/lib/python3.8/site-packages/gluoncv/auto/estimators/torch_image_classification/torch_image_classification.py\", '\n               'line 123, in _fit\\n'\n               '    return self._resume_fit(train_data, val_data, '\n               'time_limit=time_limit)\\n'\n               '  File '\n               '\"/home/kate/.local/lib/python3.8/site-packages/gluoncv/auto/estimators/torch_image_classification/torch_image_classification.py\", '\n               'line 201, in _resume_fit\\n'\n               '    return self._train_loop(train_loader, val_loader, '\n               'time_limit=time_limit)\\n'\n               '  File '\n               '\"/home/kate/.local/lib/python3.8/site-packages/gluoncv/auto/estimators/torch_image_classification/torch_image_classification.py\", '\n               'line 239, in _train_loop\\n'\n               '    train_metrics = self.train_one_epoch(\\n'\n               '  File '\n               '\"/home/kate/.local/lib/python3.8/site-packages/gluoncv/auto/estimators/torch_image_classification/torch_image_classification.py\", '\n               'line 337, in train_one_epoch\\n'\n               '    output = net(input)\\n'\n               '  File '\n               '\"/home/kate/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", '\n               'line 1102, in _call_impl\\n'\n               '    return forward_call(*input, **kwargs)\\n'\n               '  File '\n               '\"/home/kate/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", '\n               'line 166, in forward\\n'\n               '    return self.module(*inputs[0], **kwargs[0])\\n'\n               '  File '\n               '\"/home/kate/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", '\n               'line 1102, in _call_impl\\n'\n               '    return forward_call(*input, **kwargs)\\n'\n               '  File '\n               '\"/home/kate/.local/lib/python3.8/site-packages/timm/models/resnet.py\", '\n               'line 685, in forward\\n'\n               '    x = self.forward_features(x)\\n'\n               '  File '\n               '\"/home/kate/.local/lib/python3.8/site-packages/timm/models/resnet.py\", '\n               'line 679, in forward_features\\n'\n               '    x = self.layer2(x)\\n'\n               '  File '\n               '\"/home/kate/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", '\n               'line 1102, in _call_impl\\n'\n               '    return forward_call(*input, **kwargs)\\n'\n               '  File '\n               '\"/home/kate/.local/lib/python3.8/site-packages/torch/nn/modules/container.py\", '\n               'line 141, in forward\\n'\n               '    input = module(input)\\n'\n               '  File '\n               '\"/home/kate/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", '\n               'line 1102, in _call_impl\\n'\n               '    return forward_call(*input, **kwargs)\\n'\n               '  File '\n               '\"/home/kate/.local/lib/python3.8/site-packages/timm/models/resnet.py\", '\n               'line 410, in forward\\n'\n               '    x = self.bn2(x)\\n'\n               '  File '\n               '\"/home/kate/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", '\n               'line 1102, in _call_impl\\n'\n               '    return forward_call(*input, **kwargs)\\n'\n               '  File '\n               '\"/home/kate/.local/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py\", '\n               'line 168, in forward\\n'\n               '    return F.batch_norm(\\n'\n               '  File '\n               '\"/home/kate/.local/lib/python3.8/site-packages/torch/nn/functional.py\", '\n               'line 2282, in batch_norm\\n'\n               '    return torch.batch_norm(\\n'\n               'RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB '\n               '(GPU 0; 1.95 GiB total capacity; 789.73 MiB already allocated; '\n               '9.88 MiB free; 822.00 MiB reserved in total by PyTorch) If '\n               'reserved memory is >> allocated memory try setting '\n               'max_split_size_mb to avoid fragmentation.  See documentation '\n               'for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n',\n  'train_acc': -1,\n  'valid_acc': -1}"
     ]
    }
   ],
   "source": [
    "predictor.fit(train_dataset, hyperparameters={'epochs': 2})  # you can trust the default config, we reduce the # epoch to save some build time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c65f5f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ag.Categorical('resnet18_v1b', 'mobilenetv3_small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "896556dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "lr = ag.Categorical(1e-2, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8158e7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters={'model': model, 'batch_size': batch_size, 'lr': lr, 'epochs': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e05ac6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ImagePredictor sets accuracy as default eval_metric for classification problems.\n",
      "Converting raw DataFrame to ImageDataset...\n",
      "Detected 6 unique classes: [0, 1, 2, 3, 4, 5]\n",
      "If you feel the `classes` is inaccurate, please construct the dataset explicitly, e.g. train_data = ImageDataset(train_data, classes=[\"foo\", \"bar\"])\n",
      "Randomly split train_data into train[12630]/validation[1404] splits.\n",
      "The number of requested GPUs is greater than the number of available GPUs.Reduce the number to 1\n",
      "Starting HPO experiments\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de8d90d6cb9f4f4d8135e904c6fb6155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=============================================================================\n",
      "WARNING: Using MXNet models in ImagePredictor is deprecated as of v0.4.0 and may contain various bugs and issues!\n",
      "In v0.5.0, ImagePredictor will no longer support training MXNet models. Please consider switching to specifying Torch models instead.\n",
      "Users should ensure they update their code that depends on ImagePredictor when upgrading to future AutoGluon releases.\n",
      "For more information, refer to this GitHub issue: https://github.com/awslabs/autogluon/issues/1560\n",
      "=============================================================================\n",
      "\n",
      "modified configs(<old> != <new>): {\n",
      "root.valid.batch_size 128 != 8\n",
      "root.valid.num_workers 4 != 12\n",
      "root.train.epochs    10 != 2\n",
      "root.train.early_stop_max_value 1.0 != inf\n",
      "root.train.num_workers 4 != 12\n",
      "root.train.lr        0.1 != 0.01\n",
      "root.train.data_dir  ~/.mxnet/datasets/imagenet != auto\n",
      "root.train.num_training_samples 1281167 != -1\n",
      "root.train.rec_train ~/.mxnet/datasets/imagenet/rec/train.rec != auto\n",
      "root.train.rec_train_idx ~/.mxnet/datasets/imagenet/rec/train.idx != auto\n",
      "root.train.rec_val_idx ~/.mxnet/datasets/imagenet/rec/val.idx != auto\n",
      "root.train.batch_size 128 != 8\n",
      "root.train.early_stop_baseline 0.0 != -inf\n",
      "root.train.early_stop_patience -1 != 10\n",
      "root.train.rec_val   ~/.mxnet/datasets/imagenet/rec/val.rec != auto\n",
      "root.img_cls.model   resnet50_v1 != resnet18_v1b\n",
      "}\n",
      "Saved config to /home/kate/PycharmProjects/image_prediction/ee5c4ba3/.trial_0/config.yaml\n",
      "[12:04:00] ../src/imperative/./imperative_utils.h:93: GPU support is disabled. Compile MXNet with USE_CUDA=1 to enable GPU support.\n",
      "No gpu detected, fallback to cpu. You can ignore this warning if this is intended.\n",
      "Start training from [Epoch 0]\n",
      "Epoch[0] Batch [49]\tSpeed: 21.243450 samples/sec\taccuracy=0.360000\tlr=0.010000\n",
      "Epoch[0] Batch [99]\tSpeed: 22.918024 samples/sec\taccuracy=0.491250\tlr=0.010000\n",
      "Epoch[0] Batch [149]\tSpeed: 24.820869 samples/sec\taccuracy=0.529167\tlr=0.010000\n",
      "Epoch[0] Batch [199]\tSpeed: 23.840527 samples/sec\taccuracy=0.557500\tlr=0.010000\n",
      "Epoch[0] Batch [249]\tSpeed: 25.614471 samples/sec\taccuracy=0.590000\tlr=0.010000\n",
      "Epoch[0] Batch [299]\tSpeed: 23.904486 samples/sec\taccuracy=0.612083\tlr=0.010000\n",
      "Epoch[0] Batch [349]\tSpeed: 23.800388 samples/sec\taccuracy=0.627143\tlr=0.010000\n",
      "Epoch[0] Batch [399]\tSpeed: 23.352130 samples/sec\taccuracy=0.638125\tlr=0.010000\n",
      "Epoch[0] Batch [449]\tSpeed: 23.867154 samples/sec\taccuracy=0.648889\tlr=0.010000\n",
      "Epoch[0] Batch [499]\tSpeed: 25.971374 samples/sec\taccuracy=0.659000\tlr=0.010000\n",
      "Epoch[0] Batch [549]\tSpeed: 22.686826 samples/sec\taccuracy=0.669318\tlr=0.010000\n",
      "Epoch[0] Batch [599]\tSpeed: 22.387921 samples/sec\taccuracy=0.674167\tlr=0.010000\n",
      "Epoch[0] Batch [649]\tSpeed: 23.733614 samples/sec\taccuracy=0.680385\tlr=0.010000\n",
      "Epoch[0] Batch [699]\tSpeed: 22.820898 samples/sec\taccuracy=0.683036\tlr=0.010000\n",
      "Epoch[0] Batch [749]\tSpeed: 25.369035 samples/sec\taccuracy=0.686667\tlr=0.010000\n",
      "Epoch[0] Batch [799]\tSpeed: 24.005829 samples/sec\taccuracy=0.691094\tlr=0.010000\n",
      "Epoch[0] Batch [849]\tSpeed: 23.823595 samples/sec\taccuracy=0.693382\tlr=0.010000\n",
      "Epoch[0] Batch [899]\tSpeed: 22.976657 samples/sec\taccuracy=0.697500\tlr=0.010000\n",
      "Epoch[0] Batch [949]\tSpeed: 24.138033 samples/sec\taccuracy=0.699868\tlr=0.010000\n",
      "Epoch[0] Batch [999]\tSpeed: 24.455245 samples/sec\taccuracy=0.700125\tlr=0.010000\n",
      "Epoch[0] Batch [1049]\tSpeed: 24.629514 samples/sec\taccuracy=0.704524\tlr=0.010000\n",
      "Epoch[0] Batch [1099]\tSpeed: 23.910693 samples/sec\taccuracy=0.708182\tlr=0.010000\n",
      "Epoch[0] Batch [1149]\tSpeed: 24.605383 samples/sec\taccuracy=0.713043\tlr=0.010000\n",
      "Epoch[0] Batch [1199]\tSpeed: 24.098968 samples/sec\taccuracy=0.714063\tlr=0.010000\n",
      "Epoch[0] Batch [1249]\tSpeed: 24.358498 samples/sec\taccuracy=0.716500\tlr=0.010000\n",
      "Epoch[0] Batch [1299]\tSpeed: 24.572221 samples/sec\taccuracy=0.719231\tlr=0.010000\n",
      "Epoch[0] Batch [1349]\tSpeed: 25.035891 samples/sec\taccuracy=0.722685\tlr=0.010000\n",
      "Epoch[0] Batch [1399]\tSpeed: 25.349626 samples/sec\taccuracy=0.725268\tlr=0.010000\n",
      "Epoch[0] Batch [1449]\tSpeed: 24.096052 samples/sec\taccuracy=0.726724\tlr=0.010000\n",
      "Epoch[0] Batch [1499]\tSpeed: 24.426828 samples/sec\taccuracy=0.729333\tlr=0.010000\n",
      "Epoch[0] Batch [1549]\tSpeed: 23.097127 samples/sec\taccuracy=0.731935\tlr=0.010000\n",
      "[Epoch 0] training: accuracy=0.733286\n",
      "[Epoch 0] speed: 23 samples/sec\ttime cost: 527.511516\n",
      "[Epoch 0] validation: top1=0.891738 top5=0.999288\n",
      "[Epoch 0] Current best top-1: 0.891738 vs previous -inf, saved to /home/kate/PycharmProjects/image_prediction/ee5c4ba3/.trial_0/best_checkpoint.pkl\n",
      "Epoch[1] Batch [49]\tSpeed: 24.475034 samples/sec\taccuracy=0.802500\tlr=0.010000\n",
      "Epoch[1] Batch [99]\tSpeed: 25.332459 samples/sec\taccuracy=0.786250\tlr=0.010000\n",
      "Epoch[1] Batch [149]\tSpeed: 22.682413 samples/sec\taccuracy=0.775000\tlr=0.010000\n",
      "`time_limit=599.9759533405304` reached, exit early...\n",
      "Applying the state from the best checkpoint...\n",
      "[12:14:07] ../src/imperative/./imperative_utils.h:93: GPU support is disabled. Compile MXNet with USE_CUDA=1 to enable GPU support.\n",
      "\tStopping HPO to satisfy time limit...\n",
      "=============================================================================\n",
      "WARNING: Using MXNet models in ImagePredictor is deprecated as of v0.4.0 and may contain various bugs and issues!\n",
      "In v0.5.0, ImagePredictor will no longer support training MXNet models. Please consider switching to specifying Torch models instead.\n",
      "Users should ensure they update their code that depends on ImagePredictor when upgrading to future AutoGluon releases.\n",
      "For more information, refer to this GitHub issue: https://github.com/awslabs/autogluon/issues/1560\n",
      "=============================================================================\n",
      "\n",
      "[12:14:08] ../src/imperative/./imperative_utils.h:93: GPU support is disabled. Compile MXNet with USE_CUDA=1 to enable GPU support.\n",
      "Saving Training Curve in /home/kate/PycharmProjects/image_prediction/ee5c4ba3/plot_training_curves.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finished, total runtime is 609.44 s\n",
      "{ 'best_config': { 'estimator': <class 'gluoncv.auto.estimators.image_classification.image_classification.ImageClassificationEstimator'>,\n",
      "                   'gpus': [0],\n",
      "                   'img_cls': { 'batch_norm': False,\n",
      "                                'last_gamma': False,\n",
      "                                'model': 'resnet18_v1b',\n",
      "                                'use_gn': False,\n",
      "                                'use_pretrained': True,\n",
      "                                'use_se': False},\n",
      "                   'train': { 'batch_size': 8,\n",
      "                              'crop_ratio': 0.875,\n",
      "                              'data_dir': 'auto',\n",
      "                              'dtype': 'float32',\n",
      "                              'early_stop_baseline': -inf,\n",
      "                              'early_stop_max_value': inf,\n",
      "                              'early_stop_min_delta': 0.001,\n",
      "                              'early_stop_patience': 10,\n",
      "                              'epochs': 2,\n",
      "                              'hard_weight': 0.5,\n",
      "                              'input_size': 224,\n",
      "                              'label_smoothing': False,\n",
      "                              'log_interval': 50,\n",
      "                              'lr': 0.01,\n",
      "                              'lr_decay': 0.1,\n",
      "                              'lr_decay_epoch': '40, 60',\n",
      "                              'lr_decay_period': 0,\n",
      "                              'lr_mode': 'step',\n",
      "                              'mixup': False,\n",
      "                              'mixup_alpha': 0.2,\n",
      "                              'mixup_off_epoch': 0,\n",
      "                              'mode': '',\n",
      "                              'momentum': 0.9,\n",
      "                              'no_wd': False,\n",
      "                              'num_training_samples': -1,\n",
      "                              'num_workers': 12,\n",
      "                              'output_lr_mult': 0.1,\n",
      "                              'pretrained_base': True,\n",
      "                              'rec_train': 'auto',\n",
      "                              'rec_train_idx': 'auto',\n",
      "                              'rec_val': 'auto',\n",
      "                              'rec_val_idx': 'auto',\n",
      "                              'resume_epoch': 0,\n",
      "                              'start_epoch': 0,\n",
      "                              'teacher': None,\n",
      "                              'temperature': 20,\n",
      "                              'transfer_lr_mult': 0.01,\n",
      "                              'use_rec': False,\n",
      "                              'warmup_epochs': 0,\n",
      "                              'warmup_lr': 0.0,\n",
      "                              'wd': 0.0001},\n",
      "                   'valid': {'batch_size': 8, 'num_workers': 12}},\n",
      "  'total_time': 609.0380098819733,\n",
      "  'train_acc': 0.775,\n",
      "  'valid_acc': 0.8917378917378918}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 val acc: 0.892\n"
     ]
    }
   ],
   "source": [
    "hyperparameters={'model': model, 'batch_size': batch_size, 'lr': lr, 'epochs': 2}\n",
    "predictor = ImagePredictor()\n",
    "predictor.fit(train_dataset, time_limit=60*10, hyperparameters=hyperparameters,\n",
    "              hyperparameter_tune_kwargs={'num_trials': 2})\n",
    "print('Top-1 val acc: %.3f' % predictor.fit_summary()['valid_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ae750201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 train acc: 0.775, val acc: 0.892\n"
     ]
    }
   ],
   "source": [
    "fit_result = predictor.fit_summary()\n",
    "print('Top-1 train acc: %.3f, val acc: %.3f' %(fit_result['train_acc'], fit_result['valid_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9509500c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'seg_pred'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3b359479",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_images = os.listdir(os.path.join(base_path,folders[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9c1e9b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['21326.jpg',\n",
       " '5803.jpg',\n",
       " '12901.jpg',\n",
       " '7943.jpg',\n",
       " '677.jpg',\n",
       " '22049.jpg',\n",
       " '12033.jpg',\n",
       " '10434.jpg',\n",
       " '5229.jpg',\n",
       " '19065.jpg',\n",
       " '17115.jpg',\n",
       " '13438.jpg',\n",
       " '16158.jpg',\n",
       " '5550.jpg',\n",
       " '16558.jpg',\n",
       " '9030.jpg',\n",
       " '10901.jpg',\n",
       " '1624.jpg',\n",
       " '23832.jpg',\n",
       " '9772.jpg',\n",
       " '11909.jpg',\n",
       " '9205.jpg',\n",
       " '15004.jpg',\n",
       " '4643.jpg',\n",
       " '5520.jpg',\n",
       " '21953.jpg',\n",
       " '4023.jpg',\n",
       " '16825.jpg',\n",
       " '7310.jpg',\n",
       " '22999.jpg',\n",
       " '22521.jpg',\n",
       " '507.jpg',\n",
       " '6229.jpg',\n",
       " '2278.jpg',\n",
       " '19393.jpg',\n",
       " '9264.jpg',\n",
       " '6892.jpg',\n",
       " '8971.jpg',\n",
       " '12635.jpg',\n",
       " '20823.jpg',\n",
       " '3408.jpg',\n",
       " '23034.jpg',\n",
       " '3772.jpg',\n",
       " '13807.jpg',\n",
       " '19941.jpg',\n",
       " '8597.jpg',\n",
       " '11022.jpg',\n",
       " '19376.jpg',\n",
       " '23994.jpg',\n",
       " '5945.jpg',\n",
       " '18608.jpg',\n",
       " '22605.jpg',\n",
       " '1376.jpg',\n",
       " '17804.jpg',\n",
       " '11170.jpg',\n",
       " '7869.jpg',\n",
       " '7663.jpg',\n",
       " '2376.jpg',\n",
       " '3833.jpg',\n",
       " '11778.jpg',\n",
       " '9168.jpg',\n",
       " '22492.jpg',\n",
       " '8154.jpg',\n",
       " '12960.jpg',\n",
       " '20103.jpg',\n",
       " '2146.jpg',\n",
       " '24289.jpg',\n",
       " '13199.jpg',\n",
       " '6.jpg',\n",
       " '4562.jpg',\n",
       " '8972.jpg',\n",
       " '8423.jpg',\n",
       " '22749.jpg',\n",
       " '9428.jpg',\n",
       " '13510.jpg',\n",
       " '16626.jpg',\n",
       " '4324.jpg',\n",
       " '16816.jpg',\n",
       " '9641.jpg',\n",
       " '4201.jpg',\n",
       " '22069.jpg',\n",
       " '10477.jpg',\n",
       " '17976.jpg',\n",
       " '14814.jpg',\n",
       " '5756.jpg',\n",
       " '9491.jpg',\n",
       " '5864.jpg',\n",
       " '23485.jpg',\n",
       " '19062.jpg',\n",
       " '4931.jpg',\n",
       " '5367.jpg',\n",
       " '20219.jpg',\n",
       " '3570.jpg',\n",
       " '350.jpg',\n",
       " '13454.jpg',\n",
       " '11353.jpg',\n",
       " '4984.jpg',\n",
       " '17917.jpg',\n",
       " '6250.jpg',\n",
       " '21332.jpg',\n",
       " '2899.jpg',\n",
       " '20849.jpg',\n",
       " '1631.jpg',\n",
       " '6419.jpg',\n",
       " '1164.jpg',\n",
       " '10960.jpg',\n",
       " '10538.jpg',\n",
       " '14169.jpg',\n",
       " '499.jpg',\n",
       " '11798.jpg',\n",
       " '8505.jpg',\n",
       " '8110.jpg',\n",
       " '17720.jpg',\n",
       " '4588.jpg',\n",
       " '22055.jpg',\n",
       " '831.jpg',\n",
       " '1405.jpg',\n",
       " '9933.jpg',\n",
       " '4660.jpg',\n",
       " '9257.jpg',\n",
       " '22206.jpg',\n",
       " '4701.jpg',\n",
       " '20488.jpg',\n",
       " '12921.jpg',\n",
       " '22841.jpg',\n",
       " '1223.jpg',\n",
       " '15315.jpg',\n",
       " '10211.jpg',\n",
       " '11527.jpg',\n",
       " '15786.jpg',\n",
       " '13929.jpg',\n",
       " '9128.jpg',\n",
       " '20182.jpg',\n",
       " '10269.jpg',\n",
       " '23132.jpg',\n",
       " '15737.jpg',\n",
       " '720.jpg',\n",
       " '3966.jpg',\n",
       " '22344.jpg',\n",
       " '22435.jpg',\n",
       " '23145.jpg',\n",
       " '9440.jpg',\n",
       " '21548.jpg',\n",
       " '19128.jpg',\n",
       " '19258.jpg',\n",
       " '15846.jpg',\n",
       " '11038.jpg',\n",
       " '6769.jpg',\n",
       " '19725.jpg',\n",
       " '20682.jpg',\n",
       " '1279.jpg',\n",
       " '365.jpg',\n",
       " '23086.jpg',\n",
       " '19188.jpg',\n",
       " '11695.jpg',\n",
       " '21521.jpg',\n",
       " '3421.jpg',\n",
       " '5953.jpg',\n",
       " '14878.jpg',\n",
       " '15881.jpg',\n",
       " '7186.jpg',\n",
       " '10124.jpg',\n",
       " '11619.jpg',\n",
       " '2237.jpg',\n",
       " '9986.jpg',\n",
       " '15830.jpg',\n",
       " '17637.jpg',\n",
       " '11802.jpg',\n",
       " '12394.jpg',\n",
       " '21566.jpg',\n",
       " '2033.jpg',\n",
       " '8678.jpg',\n",
       " '8272.jpg',\n",
       " '7356.jpg',\n",
       " '9992.jpg',\n",
       " '3612.jpg',\n",
       " '16784.jpg',\n",
       " '4204.jpg',\n",
       " '17012.jpg',\n",
       " '9421.jpg',\n",
       " '22174.jpg',\n",
       " '5766.jpg',\n",
       " '6145.jpg',\n",
       " '9557.jpg',\n",
       " '5936.jpg',\n",
       " '14149.jpg',\n",
       " '18459.jpg',\n",
       " '592.jpg',\n",
       " '18537.jpg',\n",
       " '2812.jpg',\n",
       " '6329.jpg',\n",
       " '14206.jpg',\n",
       " '12841.jpg',\n",
       " '16619.jpg',\n",
       " '9354.jpg',\n",
       " '15162.jpg',\n",
       " '19409.jpg',\n",
       " '15438.jpg',\n",
       " '9178.jpg',\n",
       " '17859.jpg',\n",
       " '3823.jpg',\n",
       " '9876.jpg',\n",
       " '17763.jpg',\n",
       " '21681.jpg',\n",
       " '21460.jpg',\n",
       " '22509.jpg',\n",
       " '15200.jpg',\n",
       " '23839.jpg',\n",
       " '930.jpg',\n",
       " '4424.jpg',\n",
       " '17565.jpg',\n",
       " '20743.jpg',\n",
       " '1935.jpg',\n",
       " '10187.jpg',\n",
       " '17595.jpg',\n",
       " '22863.jpg',\n",
       " '6017.jpg',\n",
       " '3814.jpg',\n",
       " '6822.jpg',\n",
       " '3710.jpg',\n",
       " '23921.jpg',\n",
       " '21202.jpg',\n",
       " '22584.jpg',\n",
       " '10749.jpg',\n",
       " '22407.jpg',\n",
       " '11968.jpg',\n",
       " '12582.jpg',\n",
       " '15027.jpg',\n",
       " '1949.jpg',\n",
       " '22922.jpg',\n",
       " '23674.jpg',\n",
       " '5975.jpg',\n",
       " '1561.jpg',\n",
       " '21946.jpg',\n",
       " '21667.jpg',\n",
       " '5871.jpg',\n",
       " '11564.jpg',\n",
       " '13476.jpg',\n",
       " '18998.jpg',\n",
       " '7395.jpg',\n",
       " '6733.jpg',\n",
       " '15023.jpg',\n",
       " '14253.jpg',\n",
       " '21693.jpg',\n",
       " '20032.jpg',\n",
       " '13330.jpg',\n",
       " '10395.jpg',\n",
       " '21056.jpg',\n",
       " '121.jpg',\n",
       " '7092.jpg',\n",
       " '4823.jpg',\n",
       " '11942.jpg',\n",
       " '17108.jpg',\n",
       " '23768.jpg',\n",
       " '15010.jpg',\n",
       " '4072.jpg',\n",
       " '9508.jpg',\n",
       " '13457.jpg',\n",
       " '17710.jpg',\n",
       " '22937.jpg',\n",
       " '1897.jpg',\n",
       " '9374.jpg',\n",
       " '939.jpg',\n",
       " '4921.jpg',\n",
       " '10652.jpg',\n",
       " '1536.jpg',\n",
       " '798.jpg',\n",
       " '4510.jpg',\n",
       " '1414.jpg',\n",
       " '24003.jpg',\n",
       " '14112.jpg',\n",
       " '10147.jpg',\n",
       " '13867.jpg',\n",
       " '8215.jpg',\n",
       " '20201.jpg',\n",
       " '12867.jpg',\n",
       " '5491.jpg',\n",
       " '23410.jpg',\n",
       " '2438.jpg',\n",
       " '3171.jpg',\n",
       " '11793.jpg',\n",
       " '12980.jpg',\n",
       " '21590.jpg',\n",
       " '23627.jpg',\n",
       " '5847.jpg',\n",
       " '2813.jpg',\n",
       " '6113.jpg',\n",
       " '14589.jpg',\n",
       " '3478.jpg',\n",
       " '19287.jpg',\n",
       " '9092.jpg',\n",
       " '12153.jpg',\n",
       " '18985.jpg',\n",
       " '5137.jpg',\n",
       " '20324.jpg',\n",
       " '1048.jpg',\n",
       " '18404.jpg',\n",
       " '14051.jpg',\n",
       " '8967.jpg',\n",
       " '11243.jpg',\n",
       " '9945.jpg',\n",
       " '130.jpg',\n",
       " '15357.jpg',\n",
       " '18987.jpg',\n",
       " '21308.jpg',\n",
       " '72.jpg',\n",
       " '22662.jpg',\n",
       " '1652.jpg',\n",
       " '17800.jpg',\n",
       " '6857.jpg',\n",
       " '23479.jpg',\n",
       " '22551.jpg',\n",
       " '18297.jpg',\n",
       " '18800.jpg',\n",
       " '2025.jpg',\n",
       " '23864.jpg',\n",
       " '22396.jpg',\n",
       " '7567.jpg',\n",
       " '6924.jpg',\n",
       " '3565.jpg',\n",
       " '17358.jpg',\n",
       " '16886.jpg',\n",
       " '15427.jpg',\n",
       " '12253.jpg',\n",
       " '20192.jpg',\n",
       " '4355.jpg',\n",
       " '7194.jpg',\n",
       " '18148.jpg',\n",
       " '4190.jpg',\n",
       " '10270.jpg',\n",
       " '12041.jpg',\n",
       " '21690.jpg',\n",
       " '14236.jpg',\n",
       " '4793.jpg',\n",
       " '18250.jpg',\n",
       " '18650.jpg',\n",
       " '10366.jpg',\n",
       " '24048.jpg',\n",
       " '14204.jpg',\n",
       " '21822.jpg',\n",
       " '13475.jpg',\n",
       " '12850.jpg',\n",
       " '23607.jpg',\n",
       " '11596.jpg',\n",
       " '21975.jpg',\n",
       " '21833.jpg',\n",
       " '13696.jpg',\n",
       " '2046.jpg',\n",
       " '4074.jpg',\n",
       " '18448.jpg',\n",
       " '5999.jpg',\n",
       " '6228.jpg',\n",
       " '7263.jpg',\n",
       " '5827.jpg',\n",
       " '9993.jpg',\n",
       " '8094.jpg',\n",
       " '7907.jpg',\n",
       " '13214.jpg',\n",
       " '661.jpg',\n",
       " '10479.jpg',\n",
       " '15840.jpg',\n",
       " '15825.jpg',\n",
       " '7691.jpg',\n",
       " '19759.jpg',\n",
       " '7372.jpg',\n",
       " '4395.jpg',\n",
       " '3177.jpg',\n",
       " '11481.jpg',\n",
       " '17157.jpg',\n",
       " '21830.jpg',\n",
       " '18890.jpg',\n",
       " '20132.jpg',\n",
       " '17349.jpg',\n",
       " '24306.jpg',\n",
       " '20632.jpg',\n",
       " '7631.jpg',\n",
       " '12816.jpg',\n",
       " '6251.jpg',\n",
       " '13055.jpg',\n",
       " '16477.jpg',\n",
       " '16779.jpg',\n",
       " '7770.jpg',\n",
       " '14558.jpg',\n",
       " '18434.jpg',\n",
       " '21567.jpg',\n",
       " '2977.jpg',\n",
       " '11588.jpg',\n",
       " '4278.jpg',\n",
       " '21327.jpg',\n",
       " '20772.jpg',\n",
       " '11087.jpg',\n",
       " '15148.jpg',\n",
       " '609.jpg',\n",
       " '8893.jpg',\n",
       " '3517.jpg',\n",
       " '16264.jpg',\n",
       " '12261.jpg',\n",
       " '8020.jpg',\n",
       " '8718.jpg',\n",
       " '22752.jpg',\n",
       " '19473.jpg',\n",
       " '15080.jpg',\n",
       " '3206.jpg',\n",
       " '6721.jpg',\n",
       " '17513.jpg',\n",
       " '12302.jpg',\n",
       " '7435.jpg',\n",
       " '16546.jpg',\n",
       " '4876.jpg',\n",
       " '9075.jpg',\n",
       " '7407.jpg',\n",
       " '2128.jpg',\n",
       " '10685.jpg',\n",
       " '16299.jpg',\n",
       " '6288.jpg',\n",
       " '14939.jpg',\n",
       " '11984.jpg',\n",
       " '6308.jpg',\n",
       " '995.jpg',\n",
       " '9950.jpg',\n",
       " '15485.jpg',\n",
       " '7352.jpg',\n",
       " '13255.jpg',\n",
       " '7768.jpg',\n",
       " '11971.jpg',\n",
       " '19919.jpg',\n",
       " '4545.jpg',\n",
       " '13237.jpg',\n",
       " '13399.jpg',\n",
       " '14098.jpg',\n",
       " '13663.jpg',\n",
       " '12354.jpg',\n",
       " '18121.jpg',\n",
       " '18719.jpg',\n",
       " '13458.jpg',\n",
       " '10530.jpg',\n",
       " '9187.jpg',\n",
       " '4784.jpg',\n",
       " '18806.jpg',\n",
       " '754.jpg',\n",
       " '3335.jpg',\n",
       " '12115.jpg',\n",
       " '9500.jpg',\n",
       " '10333.jpg',\n",
       " '23030.jpg',\n",
       " '389.jpg',\n",
       " '15391.jpg',\n",
       " '15805.jpg',\n",
       " '15442.jpg',\n",
       " '16275.jpg',\n",
       " '16777.jpg',\n",
       " '5314.jpg',\n",
       " '4697.jpg',\n",
       " '2620.jpg',\n",
       " '10987.jpg',\n",
       " '8593.jpg',\n",
       " '18695.jpg',\n",
       " '9398.jpg',\n",
       " '2664.jpg',\n",
       " '13683.jpg',\n",
       " '7864.jpg',\n",
       " '18649.jpg',\n",
       " '23074.jpg',\n",
       " '24142.jpg',\n",
       " '22946.jpg',\n",
       " '17471.jpg',\n",
       " '18254.jpg',\n",
       " '15351.jpg',\n",
       " '12073.jpg',\n",
       " '9452.jpg',\n",
       " '23152.jpg',\n",
       " '2317.jpg',\n",
       " '8004.jpg',\n",
       " '13591.jpg',\n",
       " '23364.jpg',\n",
       " '7426.jpg',\n",
       " '8463.jpg',\n",
       " '7149.jpg',\n",
       " '4021.jpg',\n",
       " '11445.jpg',\n",
       " '1427.jpg',\n",
       " '22080.jpg',\n",
       " '10410.jpg',\n",
       " '13469.jpg',\n",
       " '6612.jpg',\n",
       " '10760.jpg',\n",
       " '16514.jpg',\n",
       " '8432.jpg',\n",
       " '6988.jpg',\n",
       " '21223.jpg',\n",
       " '14793.jpg',\n",
       " '21528.jpg',\n",
       " '588.jpg',\n",
       " '16713.jpg',\n",
       " '3096.jpg',\n",
       " '8802.jpg',\n",
       " '15733.jpg',\n",
       " '7592.jpg',\n",
       " '20237.jpg',\n",
       " '12959.jpg',\n",
       " '10829.jpg',\n",
       " '12879.jpg',\n",
       " '2956.jpg',\n",
       " '3716.jpg',\n",
       " '11715.jpg',\n",
       " '1525.jpg',\n",
       " '23231.jpg',\n",
       " '656.jpg',\n",
       " '19385.jpg',\n",
       " '6248.jpg',\n",
       " '17310.jpg',\n",
       " '19877.jpg',\n",
       " '18513.jpg',\n",
       " '4405.jpg',\n",
       " '3393.jpg',\n",
       " '10190.jpg',\n",
       " '19869.jpg',\n",
       " '6715.jpg',\n",
       " '23895.jpg',\n",
       " '3580.jpg',\n",
       " '12501.jpg',\n",
       " '22787.jpg',\n",
       " '572.jpg',\n",
       " '951.jpg',\n",
       " '17388.jpg',\n",
       " '19229.jpg',\n",
       " '17256.jpg',\n",
       " '11123.jpg',\n",
       " '19501.jpg',\n",
       " '13488.jpg',\n",
       " '4615.jpg',\n",
       " '22772.jpg',\n",
       " '13176.jpg',\n",
       " '16461.jpg',\n",
       " '13718.jpg',\n",
       " '826.jpg',\n",
       " '12351.jpg',\n",
       " '570.jpg',\n",
       " '6582.jpg',\n",
       " '4649.jpg',\n",
       " '7750.jpg',\n",
       " '20278.jpg',\n",
       " '10038.jpg',\n",
       " '16747.jpg',\n",
       " '19856.jpg',\n",
       " '15396.jpg',\n",
       " '20594.jpg',\n",
       " '18058.jpg',\n",
       " '19346.jpg',\n",
       " '1016.jpg',\n",
       " '6082.jpg',\n",
       " '12966.jpg',\n",
       " '17535.jpg',\n",
       " '14696.jpg',\n",
       " '2286.jpg',\n",
       " '6783.jpg',\n",
       " '9982.jpg',\n",
       " '13460.jpg',\n",
       " '10391.jpg',\n",
       " '14387.jpg',\n",
       " '20146.jpg',\n",
       " '15366.jpg',\n",
       " '14901.jpg',\n",
       " '22359.jpg',\n",
       " '18414.jpg',\n",
       " '13471.jpg',\n",
       " '11397.jpg',\n",
       " '5639.jpg',\n",
       " '2373.jpg',\n",
       " '8730.jpg',\n",
       " '17650.jpg',\n",
       " '6717.jpg',\n",
       " '17281.jpg',\n",
       " '5645.jpg',\n",
       " '2023.jpg',\n",
       " '12842.jpg',\n",
       " '17931.jpg',\n",
       " '8704.jpg',\n",
       " '6739.jpg',\n",
       " '14842.jpg',\n",
       " '19008.jpg',\n",
       " '12459.jpg',\n",
       " '885.jpg',\n",
       " '11216.jpg',\n",
       " '24276.jpg',\n",
       " '11101.jpg',\n",
       " '4503.jpg',\n",
       " '10910.jpg',\n",
       " '9245.jpg',\n",
       " '13459.jpg',\n",
       " '6794.jpg',\n",
       " '22334.jpg',\n",
       " '4353.jpg',\n",
       " '4702.jpg',\n",
       " '732.jpg',\n",
       " '4592.jpg',\n",
       " '4993.jpg',\n",
       " '2694.jpg',\n",
       " '19012.jpg',\n",
       " '8106.jpg',\n",
       " '22081.jpg',\n",
       " '24326.jpg',\n",
       " '10069.jpg',\n",
       " '8405.jpg',\n",
       " '20021.jpg',\n",
       " '13299.jpg',\n",
       " '18482.jpg',\n",
       " '2920.jpg',\n",
       " '21003.jpg',\n",
       " '4326.jpg',\n",
       " '4538.jpg',\n",
       " '4721.jpg',\n",
       " '794.jpg',\n",
       " '20364.jpg',\n",
       " '23054.jpg',\n",
       " '17601.jpg',\n",
       " '4300.jpg',\n",
       " '13550.jpg',\n",
       " '5113.jpg',\n",
       " '8101.jpg',\n",
       " '23439.jpg',\n",
       " '18241.jpg',\n",
       " '15113.jpg',\n",
       " '17974.jpg',\n",
       " '22751.jpg',\n",
       " '13169.jpg',\n",
       " '14240.jpg',\n",
       " '4416.jpg',\n",
       " '24233.jpg',\n",
       " '1200.jpg',\n",
       " '5859.jpg',\n",
       " '18326.jpg',\n",
       " '9248.jpg',\n",
       " '10048.jpg',\n",
       " '8443.jpg',\n",
       " '1364.jpg',\n",
       " '11886.jpg',\n",
       " '2533.jpg',\n",
       " '4229.jpg',\n",
       " '12498.jpg',\n",
       " '17159.jpg',\n",
       " '7273.jpg',\n",
       " '17100.jpg',\n",
       " '6930.jpg',\n",
       " '6450.jpg',\n",
       " '3413.jpg',\n",
       " '11167.jpg',\n",
       " '16850.jpg',\n",
       " '12557.jpg',\n",
       " '22698.jpg',\n",
       " '16343.jpg',\n",
       " '1322.jpg',\n",
       " '6069.jpg',\n",
       " '7156.jpg',\n",
       " '20758.jpg',\n",
       " '7444.jpg',\n",
       " '4917.jpg',\n",
       " '8887.jpg',\n",
       " '15619.jpg',\n",
       " '4664.jpg',\n",
       " '17271.jpg',\n",
       " '15489.jpg',\n",
       " '21205.jpg',\n",
       " '9465.jpg',\n",
       " '2685.jpg',\n",
       " '1655.jpg',\n",
       " '4185.jpg',\n",
       " '15068.jpg',\n",
       " '14524.jpg',\n",
       " '22554.jpg',\n",
       " '6253.jpg',\n",
       " '8988.jpg',\n",
       " '20792.jpg',\n",
       " '1102.jpg',\n",
       " '1444.jpg',\n",
       " '19148.jpg',\n",
       " '12305.jpg',\n",
       " '2060.jpg',\n",
       " '22549.jpg',\n",
       " '4677.jpg',\n",
       " '18376.jpg',\n",
       " '21963.jpg',\n",
       " '5469.jpg',\n",
       " '24104.jpg',\n",
       " '2696.jpg',\n",
       " '19870.jpg',\n",
       " '5882.jpg',\n",
       " '23897.jpg',\n",
       " '19569.jpg',\n",
       " '15602.jpg',\n",
       " '4867.jpg',\n",
       " '10558.jpg',\n",
       " '11431.jpg',\n",
       " '11915.jpg',\n",
       " '6943.jpg',\n",
       " '23238.jpg',\n",
       " '10209.jpg',\n",
       " '9515.jpg',\n",
       " '17369.jpg',\n",
       " '18346.jpg',\n",
       " '14276.jpg',\n",
       " '6202.jpg',\n",
       " '21922.jpg',\n",
       " '18961.jpg',\n",
       " '18847.jpg',\n",
       " '4732.jpg',\n",
       " '16263.jpg',\n",
       " '13520.jpg',\n",
       " '14200.jpg',\n",
       " '7260.jpg',\n",
       " '6410.jpg',\n",
       " '777.jpg',\n",
       " '19797.jpg',\n",
       " '6882.jpg',\n",
       " '11078.jpg',\n",
       " '4681.jpg',\n",
       " '19194.jpg',\n",
       " '2865.jpg',\n",
       " '23081.jpg',\n",
       " '11581.jpg',\n",
       " '17279.jpg',\n",
       " '3445.jpg',\n",
       " '16878.jpg',\n",
       " '10288.jpg',\n",
       " '388.jpg',\n",
       " '18616.jpg',\n",
       " '5380.jpg',\n",
       " '579.jpg',\n",
       " '20376.jpg',\n",
       " '20097.jpg',\n",
       " '13246.jpg',\n",
       " '8369.jpg',\n",
       " '7497.jpg',\n",
       " '12831.jpg',\n",
       " '1712.jpg',\n",
       " '13914.jpg',\n",
       " '5004.jpg',\n",
       " '21708.jpg',\n",
       " '23007.jpg',\n",
       " '17436.jpg',\n",
       " '5486.jpg',\n",
       " '19366.jpg',\n",
       " '12095.jpg',\n",
       " '7548.jpg',\n",
       " '11147.jpg',\n",
       " '21164.jpg',\n",
       " '6162.jpg',\n",
       " '22238.jpg',\n",
       " '11854.jpg',\n",
       " '14657.jpg',\n",
       " '10873.jpg',\n",
       " '18172.jpg',\n",
       " '8632.jpg',\n",
       " '6246.jpg',\n",
       " '9824.jpg',\n",
       " '9638.jpg',\n",
       " '23664.jpg',\n",
       " '2248.jpg',\n",
       " '12184.jpg',\n",
       " '15007.jpg',\n",
       " '24067.jpg',\n",
       " '22770.jpg',\n",
       " '16690.jpg',\n",
       " '7613.jpg',\n",
       " '9796.jpg',\n",
       " '9183.jpg',\n",
       " '10733.jpg',\n",
       " '17802.jpg',\n",
       " '16058.jpg',\n",
       " '17186.jpg',\n",
       " '15896.jpg',\n",
       " '12132.jpg',\n",
       " '6191.jpg',\n",
       " '16851.jpg',\n",
       " '12606.jpg',\n",
       " '19191.jpg',\n",
       " '13260.jpg',\n",
       " '24065.jpg',\n",
       " '271.jpg',\n",
       " '362.jpg',\n",
       " '6974.jpg',\n",
       " '18033.jpg',\n",
       " '1568.jpg',\n",
       " '1934.jpg',\n",
       " '6304.jpg',\n",
       " '3714.jpg',\n",
       " '21444.jpg',\n",
       " '22365.jpg',\n",
       " '15399.jpg',\n",
       " '23198.jpg',\n",
       " '20119.jpg',\n",
       " '1214.jpg',\n",
       " '17366.jpg',\n",
       " '21739.jpg',\n",
       " '17155.jpg',\n",
       " '6094.jpg',\n",
       " '14562.jpg',\n",
       " '17231.jpg',\n",
       " '21626.jpg',\n",
       " '1174.jpg',\n",
       " '18478.jpg',\n",
       " '10307.jpg',\n",
       " '17901.jpg',\n",
       " '4434.jpg',\n",
       " '13389.jpg',\n",
       " '6218.jpg',\n",
       " '22914.jpg',\n",
       " '14613.jpg',\n",
       " '13489.jpg',\n",
       " '9626.jpg',\n",
       " '13356.jpg',\n",
       " '9397.jpg',\n",
       " '1598.jpg',\n",
       " '20814.jpg',\n",
       " '8853.jpg',\n",
       " '22728.jpg',\n",
       " '11163.jpg',\n",
       " '22901.jpg',\n",
       " '22270.jpg',\n",
       " '15829.jpg',\n",
       " '22044.jpg',\n",
       " '2039.jpg',\n",
       " '11145.jpg',\n",
       " '5.jpg',\n",
       " '11863.jpg',\n",
       " '4107.jpg',\n",
       " '497.jpg',\n",
       " '5552.jpg',\n",
       " '11126.jpg',\n",
       " '9431.jpg',\n",
       " '4816.jpg',\n",
       " '23493.jpg',\n",
       " '4925.jpg',\n",
       " '1992.jpg',\n",
       " '9476.jpg',\n",
       " '17538.jpg',\n",
       " '9326.jpg',\n",
       " '10762.jpg',\n",
       " '9144.jpg',\n",
       " '23412.jpg',\n",
       " '10436.jpg',\n",
       " '14138.jpg',\n",
       " '19427.jpg',\n",
       " '10560.jpg',\n",
       " '24054.jpg',\n",
       " '10481.jpg',\n",
       " '22932.jpg',\n",
       " '17382.jpg',\n",
       " '4286.jpg',\n",
       " '13571.jpg',\n",
       " '1255.jpg',\n",
       " '16915.jpg',\n",
       " '13561.jpg',\n",
       " '18225.jpg',\n",
       " '19646.jpg',\n",
       " '11891.jpg',\n",
       " '7110.jpg',\n",
       " '11250.jpg',\n",
       " '18981.jpg',\n",
       " '7729.jpg',\n",
       " '2396.jpg',\n",
       " '13326.jpg',\n",
       " '11328.jpg',\n",
       " '435.jpg',\n",
       " '5909.jpg',\n",
       " '6077.jpg',\n",
       " '19549.jpg',\n",
       " '1222.jpg',\n",
       " '18522.jpg',\n",
       " '15403.jpg',\n",
       " '16242.jpg',\n",
       " '21493.jpg',\n",
       " '19160.jpg',\n",
       " '14992.jpg',\n",
       " '10918.jpg',\n",
       " '18642.jpg',\n",
       " '3407.jpg',\n",
       " '1617.jpg',\n",
       " '4179.jpg',\n",
       " '19745.jpg',\n",
       " '24303.jpg',\n",
       " '1483.jpg',\n",
       " '11818.jpg',\n",
       " '4422.jpg',\n",
       " '10557.jpg',\n",
       " '16228.jpg',\n",
       " '14601.jpg',\n",
       " '18599.jpg',\n",
       " '1808.jpg',\n",
       " '18497.jpg',\n",
       " '16089.jpg',\n",
       " '22449.jpg',\n",
       " '4843.jpg',\n",
       " '7243.jpg',\n",
       " '4641.jpg',\n",
       " '18259.jpg',\n",
       " '15172.jpg',\n",
       " '8361.jpg',\n",
       " '19275.jpg',\n",
       " '10843.jpg',\n",
       " '14086.jpg',\n",
       " '14011.jpg',\n",
       " '17084.jpg',\n",
       " '18479.jpg',\n",
       " '4121.jpg',\n",
       " '22181.jpg',\n",
       " '13708.jpg',\n",
       " '9150.jpg',\n",
       " '10305.jpg',\n",
       " '13370.jpg',\n",
       " '11517.jpg',\n",
       " '19372.jpg',\n",
       " '14753.jpg',\n",
       " '15178.jpg',\n",
       " '20290.jpg',\n",
       " '7190.jpg',\n",
       " '7921.jpg',\n",
       " '12037.jpg',\n",
       " '9461.jpg',\n",
       " '17843.jpg',\n",
       " '20552.jpg',\n",
       " '11703.jpg',\n",
       " '3594.jpg',\n",
       " '13541.jpg',\n",
       " '2379.jpg',\n",
       " '302.jpg',\n",
       " '7905.jpg',\n",
       " '14241.jpg',\n",
       " '8520.jpg',\n",
       " '17405.jpg',\n",
       " '1356.jpg',\n",
       " '20217.jpg',\n",
       " '5072.jpg',\n",
       " '21235.jpg',\n",
       " '21074.jpg',\n",
       " '13641.jpg',\n",
       " '12952.jpg',\n",
       " '21374.jpg',\n",
       " '21195.jpg',\n",
       " '15229.jpg',\n",
       " '19426.jpg',\n",
       " '2554.jpg',\n",
       " '14380.jpg',\n",
       " '2701.jpg',\n",
       " '19518.jpg',\n",
       " '20492.jpg',\n",
       " '23834.jpg',\n",
       " '21219.jpg',\n",
       " '12774.jpg',\n",
       " '8829.jpg',\n",
       " '13485.jpg',\n",
       " '4136.jpg',\n",
       " '17907.jpg',\n",
       " '24255.jpg',\n",
       " '14391.jpg',\n",
       " '9293.jpg',\n",
       " '132.jpg',\n",
       " '3564.jpg',\n",
       " '8840.jpg',\n",
       " '17874.jpg',\n",
       " '19540.jpg',\n",
       " '5284.jpg',\n",
       " '8083.jpg',\n",
       " '528.jpg',\n",
       " '19742.jpg',\n",
       " '14735.jpg',\n",
       " '22981.jpg',\n",
       " '828.jpg',\n",
       " '22122.jpg',\n",
       " '10371.jpg',\n",
       " '1456.jpg',\n",
       " '12022.jpg',\n",
       " '22392.jpg',\n",
       " '19873.jpg',\n",
       " '2244.jpg',\n",
       " '19570.jpg',\n",
       " '4367.jpg',\n",
       " '4022.jpg',\n",
       " '16412.jpg',\n",
       " '12809.jpg',\n",
       " '24302.jpg',\n",
       " '17300.jpg',\n",
       " '17340.jpg',\n",
       " '3271.jpg',\n",
       " '20055.jpg',\n",
       " '11763.jpg',\n",
       " '2404.jpg',\n",
       " '13110.jpg',\n",
       " '21021.jpg',\n",
       " '21267.jpg',\n",
       " '16662.jpg',\n",
       " '11767.jpg',\n",
       " '16319.jpg',\n",
       " '5782.jpg',\n",
       " '9809.jpg',\n",
       " '9255.jpg',\n",
       " '12975.jpg',\n",
       " '17083.jpg',\n",
       " '3027.jpg',\n",
       " '10669.jpg',\n",
       " ...]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "53e23641",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.DataFrame(pred_images, columns =['Names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "184a351d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21326.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5803.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12901.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7943.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>677.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7296</th>\n",
       "      <td>14821.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7297</th>\n",
       "      <td>10855.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7298</th>\n",
       "      <td>4236.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7299</th>\n",
       "      <td>13136.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7300</th>\n",
       "      <td>23857.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7301 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Names\n",
       "0     21326.jpg\n",
       "1      5803.jpg\n",
       "2     12901.jpg\n",
       "3      7943.jpg\n",
       "4       677.jpg\n",
       "...         ...\n",
       "7296  14821.jpg\n",
       "7297  10855.jpg\n",
       "7298   4236.jpg\n",
       "7299  13136.jpg\n",
       "7300  23857.jpg\n",
       "\n",
       "[7301 rows x 1 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "df0703f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       /home/kate/PycharmProjects/image_prediction/im...\n",
       "1       /home/kate/PycharmProjects/image_prediction/im...\n",
       "2       /home/kate/PycharmProjects/image_prediction/im...\n",
       "3       /home/kate/PycharmProjects/image_prediction/im...\n",
       "4       /home/kate/PycharmProjects/image_prediction/im...\n",
       "                              ...                        \n",
       "7296    /home/kate/PycharmProjects/image_prediction/im...\n",
       "7297    /home/kate/PycharmProjects/image_prediction/im...\n",
       "7298    /home/kate/PycharmProjects/image_prediction/im...\n",
       "7299    /home/kate/PycharmProjects/image_prediction/im...\n",
       "7300    /home/kate/PycharmProjects/image_prediction/im...\n",
       "Name: Names, Length: 7301, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path+folders[2]+'/'+df_pred['Names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "39c87775",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred['image'] = base_path+folders[2]+'/'+df_pred['Names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "508868b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/kate/PycharmProjects/image_prediction/images/seg_pred/21326.jpg'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.image[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ad4ab2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = predictor.predict(df_pred.image[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2e215774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/kate/PycharmProjects/image_prediction/images/seg_pred/5803.jpg'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.image[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "34078d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = predictor.predict(df_pred.image[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "304a02c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "69b9587f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/\n",
      "├── test/\n",
      "└── train/\n",
      "                                                 image  label\n",
      "0    /home/kate/.gluoncv/datasets/shopee-iet/data/t...      0\n",
      "1    /home/kate/.gluoncv/datasets/shopee-iet/data/t...      0\n",
      "2    /home/kate/.gluoncv/datasets/shopee-iet/data/t...      0\n",
      "3    /home/kate/.gluoncv/datasets/shopee-iet/data/t...      0\n",
      "4    /home/kate/.gluoncv/datasets/shopee-iet/data/t...      0\n",
      "..                                                 ...    ...\n",
      "795  /home/kate/.gluoncv/datasets/shopee-iet/data/t...      3\n",
      "796  /home/kate/.gluoncv/datasets/shopee-iet/data/t...      3\n",
      "797  /home/kate/.gluoncv/datasets/shopee-iet/data/t...      3\n",
      "798  /home/kate/.gluoncv/datasets/shopee-iet/data/t...      3\n",
      "799  /home/kate/.gluoncv/datasets/shopee-iet/data/t...      3\n",
      "\n",
      "[800 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "train_dataset, _, test_dataset = ImageDataset.from_folders('https://autogluon.s3.amazonaws.com/datasets/shopee-iet.zip')\n",
    "print(train_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d1c3bceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/kate/.gluoncv/datasets/shopee-iet/data/t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/kate/.gluoncv/datasets/shopee-iet/data/t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/kate/.gluoncv/datasets/shopee-iet/data/t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/kate/.gluoncv/datasets/shopee-iet/data/t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/kate/.gluoncv/datasets/shopee-iet/data/t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>/home/kate/.gluoncv/datasets/shopee-iet/data/t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>/home/kate/.gluoncv/datasets/shopee-iet/data/t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>/home/kate/.gluoncv/datasets/shopee-iet/data/t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>/home/kate/.gluoncv/datasets/shopee-iet/data/t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>/home/kate/.gluoncv/datasets/shopee-iet/data/t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                image  label\n",
       "0   /home/kate/.gluoncv/datasets/shopee-iet/data/t...      0\n",
       "1   /home/kate/.gluoncv/datasets/shopee-iet/data/t...      0\n",
       "2   /home/kate/.gluoncv/datasets/shopee-iet/data/t...      0\n",
       "3   /home/kate/.gluoncv/datasets/shopee-iet/data/t...      0\n",
       "4   /home/kate/.gluoncv/datasets/shopee-iet/data/t...      0\n",
       "..                                                ...    ...\n",
       "75  /home/kate/.gluoncv/datasets/shopee-iet/data/t...      3\n",
       "76  /home/kate/.gluoncv/datasets/shopee-iet/data/t...      3\n",
       "77  /home/kate/.gluoncv/datasets/shopee-iet/data/t...      3\n",
       "78  /home/kate/.gluoncv/datasets/shopee-iet/data/t...      3\n",
       "79  /home/kate/.gluoncv/datasets/shopee-iet/data/t...      3\n",
       "\n",
       "[80 rows x 2 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "abdb758b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folders = os.listdir(os.path.join(base_path,folders[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "afadb354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sea', 'glacier', 'forest', 'mountain', 'buildings', 'street']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9463a2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_images = os.listdir(os.path.join(base_path,folders[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3416e246",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(columns =['Names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e167ddc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_folders)):\n",
    "    folder = test_folders[i]\n",
    "    a = os.listdir(os.path.join(base_path,folders[1],folder))\n",
    "    df = pd.DataFrame(a, columns =['Names'])\n",
    "    df = df.assign(Folder_Name = folder)\n",
    "    data = pd.concat([df_test, df], ignore_index=True)\n",
    "    df_test = data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "62de6a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "      <th>Folder_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20869.jpg</td>\n",
       "      <td>sea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24180.jpg</td>\n",
       "      <td>sea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20300.jpg</td>\n",
       "      <td>sea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21730.jpg</td>\n",
       "      <td>sea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20722.jpg</td>\n",
       "      <td>sea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>23155.jpg</td>\n",
       "      <td>street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>21062.jpg</td>\n",
       "      <td>street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>22786.jpg</td>\n",
       "      <td>street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>23586.jpg</td>\n",
       "      <td>street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>23795.jpg</td>\n",
       "      <td>street</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Names Folder_Name\n",
       "0     20869.jpg         sea\n",
       "1     24180.jpg         sea\n",
       "2     20300.jpg         sea\n",
       "3     21730.jpg         sea\n",
       "4     20722.jpg         sea\n",
       "...         ...         ...\n",
       "2995  23155.jpg      street\n",
       "2996  21062.jpg      street\n",
       "2997  22786.jpg      street\n",
       "2998  23586.jpg      street\n",
       "2999  23795.jpg      street\n",
       "\n",
       "[3000 rows x 2 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "35b69f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['folder_for_file'] = base_path+folders[1]+'/'+ df_test['Folder_Name']+'/'+df_test['Names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "64a64dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "      <th>Folder_Name</th>\n",
       "      <th>folder_for_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20869.jpg</td>\n",
       "      <td>sea</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24180.jpg</td>\n",
       "      <td>sea</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20300.jpg</td>\n",
       "      <td>sea</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21730.jpg</td>\n",
       "      <td>sea</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20722.jpg</td>\n",
       "      <td>sea</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>23155.jpg</td>\n",
       "      <td>street</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>21062.jpg</td>\n",
       "      <td>street</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>22786.jpg</td>\n",
       "      <td>street</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>23586.jpg</td>\n",
       "      <td>street</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>23795.jpg</td>\n",
       "      <td>street</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Names Folder_Name                                    folder_for_file\n",
       "0     20869.jpg         sea  /home/kate/PycharmProjects/image_prediction/im...\n",
       "1     24180.jpg         sea  /home/kate/PycharmProjects/image_prediction/im...\n",
       "2     20300.jpg         sea  /home/kate/PycharmProjects/image_prediction/im...\n",
       "3     21730.jpg         sea  /home/kate/PycharmProjects/image_prediction/im...\n",
       "4     20722.jpg         sea  /home/kate/PycharmProjects/image_prediction/im...\n",
       "...         ...         ...                                                ...\n",
       "2995  23155.jpg      street  /home/kate/PycharmProjects/image_prediction/im...\n",
       "2996  21062.jpg      street  /home/kate/PycharmProjects/image_prediction/im...\n",
       "2997  22786.jpg      street  /home/kate/PycharmProjects/image_prediction/im...\n",
       "2998  23586.jpg      street  /home/kate/PycharmProjects/image_prediction/im...\n",
       "2999  23795.jpg      street  /home/kate/PycharmProjects/image_prediction/im...\n",
       "\n",
       "[3000 rows x 3 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a2cdd946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_rating(folder):\n",
    "    if folder == 'glacier':\n",
    "        return (2)\n",
    "    elif folder == 'sea':\n",
    "        return (4)\n",
    "    elif folder == 'buildings':\n",
    "        return (0)\n",
    "    elif folder == 'forest':\n",
    "        return (1)\n",
    "    elif folder == 'street':\n",
    "        return (5)\n",
    "    \n",
    "    elif folder == 'mountain':\n",
    "        return (3)\n",
    "        \n",
    "df_test['label'] = df_test.Folder_Name.apply(lambda x: custom_rating(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "75ef5208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "      <th>Folder_Name</th>\n",
       "      <th>folder_for_file</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20869.jpg</td>\n",
       "      <td>sea</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24180.jpg</td>\n",
       "      <td>sea</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20300.jpg</td>\n",
       "      <td>sea</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21730.jpg</td>\n",
       "      <td>sea</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20722.jpg</td>\n",
       "      <td>sea</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>23155.jpg</td>\n",
       "      <td>street</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>21062.jpg</td>\n",
       "      <td>street</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>22786.jpg</td>\n",
       "      <td>street</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>23586.jpg</td>\n",
       "      <td>street</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>23795.jpg</td>\n",
       "      <td>street</td>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Names Folder_Name  \\\n",
       "0     20869.jpg         sea   \n",
       "1     24180.jpg         sea   \n",
       "2     20300.jpg         sea   \n",
       "3     21730.jpg         sea   \n",
       "4     20722.jpg         sea   \n",
       "...         ...         ...   \n",
       "2995  23155.jpg      street   \n",
       "2996  21062.jpg      street   \n",
       "2997  22786.jpg      street   \n",
       "2998  23586.jpg      street   \n",
       "2999  23795.jpg      street   \n",
       "\n",
       "                                        folder_for_file  label  \n",
       "0     /home/kate/PycharmProjects/image_prediction/im...      4  \n",
       "1     /home/kate/PycharmProjects/image_prediction/im...      4  \n",
       "2     /home/kate/PycharmProjects/image_prediction/im...      4  \n",
       "3     /home/kate/PycharmProjects/image_prediction/im...      4  \n",
       "4     /home/kate/PycharmProjects/image_prediction/im...      4  \n",
       "...                                                 ...    ...  \n",
       "2995  /home/kate/PycharmProjects/image_prediction/im...      5  \n",
       "2996  /home/kate/PycharmProjects/image_prediction/im...      5  \n",
       "2997  /home/kate/PycharmProjects/image_prediction/im...      5  \n",
       "2998  /home/kate/PycharmProjects/image_prediction/im...      5  \n",
       "2999  /home/kate/PycharmProjects/image_prediction/im...      5  \n",
       "\n",
       "[3000 rows x 4 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9517cbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = df_test[['folder_for_file','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0333f9b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder_for_file</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        folder_for_file  label\n",
       "0     /home/kate/PycharmProjects/image_prediction/im...      4\n",
       "1     /home/kate/PycharmProjects/image_prediction/im...      4\n",
       "2     /home/kate/PycharmProjects/image_prediction/im...      4\n",
       "3     /home/kate/PycharmProjects/image_prediction/im...      4\n",
       "4     /home/kate/PycharmProjects/image_prediction/im...      4\n",
       "...                                                 ...    ...\n",
       "2995  /home/kate/PycharmProjects/image_prediction/im...      5\n",
       "2996  /home/kate/PycharmProjects/image_prediction/im...      5\n",
       "2997  /home/kate/PycharmProjects/image_prediction/im...      5\n",
       "2998  /home/kate/PycharmProjects/image_prediction/im...      5\n",
       "2999  /home/kate/PycharmProjects/image_prediction/im...      5\n",
       "\n",
       "[3000 rows x 2 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "01775024",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = test_dataset.rename(columns={\"folder_for_file\": \"image\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8687023a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  image  label\n",
       "0     /home/kate/PycharmProjects/image_prediction/im...      4\n",
       "1     /home/kate/PycharmProjects/image_prediction/im...      4\n",
       "2     /home/kate/PycharmProjects/image_prediction/im...      4\n",
       "3     /home/kate/PycharmProjects/image_prediction/im...      4\n",
       "4     /home/kate/PycharmProjects/image_prediction/im...      4\n",
       "...                                                 ...    ...\n",
       "2995  /home/kate/PycharmProjects/image_prediction/im...      5\n",
       "2996  /home/kate/PycharmProjects/image_prediction/im...      5\n",
       "2997  /home/kate/PycharmProjects/image_prediction/im...      5\n",
       "2998  /home/kate/PycharmProjects/image_prediction/im...      5\n",
       "2999  /home/kate/PycharmProjects/image_prediction/im...      5\n",
       "\n",
       "[3000 rows x 2 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d14c4037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 test acc: 0.889\n"
     ]
    }
   ],
   "source": [
    "test_acc = predictor.evaluate(test_dataset)\n",
    "print('Top-1 test acc: %.3f' % test_acc['top1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4f3f74",
   "metadata": {},
   "source": [
    "image_path = test_dataset['image'] \n",
    "result = predictor.predict(image_path) # ValueError: Input is not supported: <class 'pandas.core.series.Series'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a6ab2e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b0f8602d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3000):\n",
    "    image_path = test_dataset.iloc[i]['image']\n",
    "    result = predictor.predict(image_path)\n",
    "    a.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f0370599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ddaad3d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(a[2999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ecccd3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(a)):\n",
    "    a[i] = int(a[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "69fd620b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "83a2f7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "47f08b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset['predict'] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2c37ad0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  image  label  predict\n",
       "0     /home/kate/PycharmProjects/image_prediction/im...      4        4\n",
       "1     /home/kate/PycharmProjects/image_prediction/im...      4        4\n",
       "2     /home/kate/PycharmProjects/image_prediction/im...      4        4\n",
       "3     /home/kate/PycharmProjects/image_prediction/im...      4        4\n",
       "4     /home/kate/PycharmProjects/image_prediction/im...      4        4\n",
       "...                                                 ...    ...      ...\n",
       "2995  /home/kate/PycharmProjects/image_prediction/im...      5        5\n",
       "2996  /home/kate/PycharmProjects/image_prediction/im...      5        5\n",
       "2997  /home/kate/PycharmProjects/image_prediction/im...      5        5\n",
       "2998  /home/kate/PycharmProjects/image_prediction/im...      5        5\n",
       "2999  /home/kate/PycharmProjects/image_prediction/im...      5        5\n",
       "\n",
       "[3000 rows x 3 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1fac63",
   "metadata": {},
   "source": [
    "#select GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = \"cpu\"  # explicitly set to execute on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3306ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save and load classifiers\n",
    "\n",
    "#You can directly save the instances of classifiers:\n",
    "\n",
    "filename = 'predictor.ag'\n",
    "predictor.save(filename)\n",
    "predictor_loaded = ImagePredictor.load(filename)\n",
    "# use predictor_loaded as usual\n",
    "result = predictor_loaded.predict(image_path)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "59fa0b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6670ece0",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_train_dataset = shuffle(train_dataset, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f40dbe6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9306</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5299</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5725</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8912</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10406</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12172</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13349</th>\n",
       "      <td>/home/kate/PycharmProjects/image_prediction/im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14034 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   image  label\n",
       "9306   /home/kate/PycharmProjects/image_prediction/im...      3\n",
       "5299   /home/kate/PycharmProjects/image_prediction/im...      1\n",
       "5725   /home/kate/PycharmProjects/image_prediction/im...      1\n",
       "8912   /home/kate/PycharmProjects/image_prediction/im...      3\n",
       "10406  /home/kate/PycharmProjects/image_prediction/im...      0\n",
       "...                                                  ...    ...\n",
       "905    /home/kate/PycharmProjects/image_prediction/im...      4\n",
       "5192   /home/kate/PycharmProjects/image_prediction/im...      1\n",
       "12172  /home/kate/PycharmProjects/image_prediction/im...      5\n",
       "235    /home/kate/PycharmProjects/image_prediction/im...      4\n",
       "13349  /home/kate/PycharmProjects/image_prediction/im...      5\n",
       "\n",
       "[14034 rows x 2 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8d712aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ImagePredictor sets accuracy as default eval_metric for classification problems.\n",
      "Converting raw DataFrame to ImageDataset...\n",
      "Detected 6 unique classes: [0, 1, 2, 3, 4, 5]\n",
      "If you feel the `classes` is inaccurate, please construct the dataset explicitly, e.g. train_data = ImageDataset(train_data, classes=[\"foo\", \"bar\"])\n",
      "Randomly split train_data into train[12630]/validation[1404] splits.\n",
      "The number of requested GPUs is greater than the number of available GPUs.Reduce the number to 1\n",
      "Starting HPO experiments\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6152ac5534b468d89689610a9390dbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=============================================================================\n",
      "WARNING: Using MXNet models in ImagePredictor is deprecated as of v0.4.0 and may contain various bugs and issues!\n",
      "In v0.5.0, ImagePredictor will no longer support training MXNet models. Please consider switching to specifying Torch models instead.\n",
      "Users should ensure they update their code that depends on ImagePredictor when upgrading to future AutoGluon releases.\n",
      "For more information, refer to this GitHub issue: https://github.com/awslabs/autogluon/issues/1560\n",
      "=============================================================================\n",
      "\n",
      "modified configs(<old> != <new>): {\n",
      "root.valid.batch_size 128 != 8\n",
      "root.valid.num_workers 4 != 12\n",
      "root.train.epochs    10 != 2\n",
      "root.train.early_stop_max_value 1.0 != inf\n",
      "root.train.num_workers 4 != 12\n",
      "root.train.lr        0.1 != 0.01\n",
      "root.train.data_dir  ~/.mxnet/datasets/imagenet != auto\n",
      "root.train.num_training_samples 1281167 != -1\n",
      "root.train.rec_train ~/.mxnet/datasets/imagenet/rec/train.rec != auto\n",
      "root.train.rec_train_idx ~/.mxnet/datasets/imagenet/rec/train.idx != auto\n",
      "root.train.rec_val_idx ~/.mxnet/datasets/imagenet/rec/val.idx != auto\n",
      "root.train.batch_size 128 != 8\n",
      "root.train.early_stop_baseline 0.0 != -inf\n",
      "root.train.early_stop_patience -1 != 10\n",
      "root.train.rec_val   ~/.mxnet/datasets/imagenet/rec/val.rec != auto\n",
      "root.img_cls.model   resnet50_v1 != resnet18_v1b\n",
      "}\n",
      "Saved config to /home/kate/PycharmProjects/image_prediction/45f873a6/.trial_0/config.yaml\n",
      "[12:38:26] ../src/imperative/./imperative_utils.h:93: GPU support is disabled. Compile MXNet with USE_CUDA=1 to enable GPU support.\n",
      "No gpu detected, fallback to cpu. You can ignore this warning if this is intended.\n",
      "Start training from [Epoch 0]\n",
      "Epoch[0] Batch [49]\tSpeed: 25.227350 samples/sec\taccuracy=0.402500\tlr=0.010000\n",
      "Epoch[0] Batch [99]\tSpeed: 24.988855 samples/sec\taccuracy=0.493750\tlr=0.010000\n",
      "Epoch[0] Batch [149]\tSpeed: 25.430174 samples/sec\taccuracy=0.542500\tlr=0.010000\n",
      "Epoch[0] Batch [199]\tSpeed: 25.085443 samples/sec\taccuracy=0.573750\tlr=0.010000\n",
      "Epoch[0] Batch [249]\tSpeed: 24.226389 samples/sec\taccuracy=0.598500\tlr=0.010000\n",
      "Epoch[0] Batch [299]\tSpeed: 20.778417 samples/sec\taccuracy=0.612083\tlr=0.010000\n",
      "Epoch[0] Batch [349]\tSpeed: 24.180339 samples/sec\taccuracy=0.628571\tlr=0.010000\n",
      "Epoch[0] Batch [399]\tSpeed: 24.385545 samples/sec\taccuracy=0.638750\tlr=0.010000\n",
      "Epoch[0] Batch [449]\tSpeed: 24.458204 samples/sec\taccuracy=0.648611\tlr=0.010000\n",
      "Epoch[0] Batch [499]\tSpeed: 23.921591 samples/sec\taccuracy=0.657250\tlr=0.010000\n",
      "Epoch[0] Batch [549]\tSpeed: 23.911459 samples/sec\taccuracy=0.664773\tlr=0.010000\n",
      "Epoch[0] Batch [599]\tSpeed: 24.107800 samples/sec\taccuracy=0.672708\tlr=0.010000\n",
      "Epoch[0] Batch [649]\tSpeed: 25.200333 samples/sec\taccuracy=0.679231\tlr=0.010000\n",
      "Epoch[0] Batch [699]\tSpeed: 22.913318 samples/sec\taccuracy=0.685357\tlr=0.010000\n",
      "Epoch[0] Batch [749]\tSpeed: 24.364893 samples/sec\taccuracy=0.689333\tlr=0.010000\n",
      "Epoch[0] Batch [799]\tSpeed: 24.936918 samples/sec\taccuracy=0.692344\tlr=0.010000\n",
      "Epoch[0] Batch [849]\tSpeed: 24.682492 samples/sec\taccuracy=0.694853\tlr=0.010000\n",
      "Epoch[0] Batch [899]\tSpeed: 24.383770 samples/sec\taccuracy=0.700972\tlr=0.010000\n",
      "Epoch[0] Batch [949]\tSpeed: 25.277232 samples/sec\taccuracy=0.703026\tlr=0.010000\n",
      "Epoch[0] Batch [999]\tSpeed: 24.029082 samples/sec\taccuracy=0.703000\tlr=0.010000\n",
      "Epoch[0] Batch [1049]\tSpeed: 24.552600 samples/sec\taccuracy=0.705833\tlr=0.010000\n",
      "Epoch[0] Batch [1099]\tSpeed: 24.940017 samples/sec\taccuracy=0.710000\tlr=0.010000\n",
      "Epoch[0] Batch [1149]\tSpeed: 24.187861 samples/sec\taccuracy=0.710761\tlr=0.010000\n",
      "Epoch[0] Batch [1199]\tSpeed: 25.480318 samples/sec\taccuracy=0.714063\tlr=0.010000\n",
      "Epoch[0] Batch [1249]\tSpeed: 25.397020 samples/sec\taccuracy=0.715800\tlr=0.010000\n",
      "Epoch[0] Batch [1299]\tSpeed: 25.670352 samples/sec\taccuracy=0.718077\tlr=0.010000\n",
      "Epoch[0] Batch [1349]\tSpeed: 24.162204 samples/sec\taccuracy=0.719259\tlr=0.010000\n",
      "Epoch[0] Batch [1399]\tSpeed: 24.118731 samples/sec\taccuracy=0.720625\tlr=0.010000\n",
      "Epoch[0] Batch [1449]\tSpeed: 24.112244 samples/sec\taccuracy=0.723707\tlr=0.010000\n",
      "Epoch[0] Batch [1499]\tSpeed: 24.636698 samples/sec\taccuracy=0.724750\tlr=0.010000\n",
      "Epoch[0] Batch [1549]\tSpeed: 25.350803 samples/sec\taccuracy=0.725645\tlr=0.010000\n",
      "[Epoch 0] training: accuracy=0.725760\n",
      "[Epoch 0] speed: 24 samples/sec\ttime cost: 516.152734\n",
      "[Epoch 0] validation: top1=0.898860 top5=1.000000\n",
      "[Epoch 0] Current best top-1: 0.898860 vs previous -inf, saved to /home/kate/PycharmProjects/image_prediction/45f873a6/.trial_0/best_checkpoint.pkl\n",
      "Epoch[1] Batch [49]\tSpeed: 21.639183 samples/sec\taccuracy=0.820000\tlr=0.010000\n",
      "Epoch[1] Batch [99]\tSpeed: 23.185673 samples/sec\taccuracy=0.778750\tlr=0.010000\n",
      "Epoch[1] Batch [149]\tSpeed: 23.122637 samples/sec\taccuracy=0.782500\tlr=0.010000\n",
      "`time_limit=599.9793691635132` reached, exit early...\n",
      "Applying the state from the best checkpoint...\n",
      "[12:48:35] ../src/imperative/./imperative_utils.h:93: GPU support is disabled. Compile MXNet with USE_CUDA=1 to enable GPU support.\n",
      "\tStopping HPO to satisfy time limit...\n",
      "=============================================================================\n",
      "WARNING: Using MXNet models in ImagePredictor is deprecated as of v0.4.0 and may contain various bugs and issues!\n",
      "In v0.5.0, ImagePredictor will no longer support training MXNet models. Please consider switching to specifying Torch models instead.\n",
      "Users should ensure they update their code that depends on ImagePredictor when upgrading to future AutoGluon releases.\n",
      "For more information, refer to this GitHub issue: https://github.com/awslabs/autogluon/issues/1560\n",
      "=============================================================================\n",
      "\n",
      "[12:48:36] ../src/imperative/./imperative_utils.h:93: GPU support is disabled. Compile MXNet with USE_CUDA=1 to enable GPU support.\n",
      "Saving Training Curve in /home/kate/PycharmProjects/image_prediction/45f873a6/plot_training_curves.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finished, total runtime is 610.24 s\n",
      "{ 'best_config': { 'estimator': <class 'gluoncv.auto.estimators.image_classification.image_classification.ImageClassificationEstimator'>,\n",
      "                   'gpus': [0],\n",
      "                   'img_cls': { 'batch_norm': False,\n",
      "                                'last_gamma': False,\n",
      "                                'model': 'resnet18_v1b',\n",
      "                                'use_gn': False,\n",
      "                                'use_pretrained': True,\n",
      "                                'use_se': False},\n",
      "                   'train': { 'batch_size': 8,\n",
      "                              'crop_ratio': 0.875,\n",
      "                              'data_dir': 'auto',\n",
      "                              'dtype': 'float32',\n",
      "                              'early_stop_baseline': -inf,\n",
      "                              'early_stop_max_value': inf,\n",
      "                              'early_stop_min_delta': 0.001,\n",
      "                              'early_stop_patience': 10,\n",
      "                              'epochs': 2,\n",
      "                              'hard_weight': 0.5,\n",
      "                              'input_size': 224,\n",
      "                              'label_smoothing': False,\n",
      "                              'log_interval': 50,\n",
      "                              'lr': 0.01,\n",
      "                              'lr_decay': 0.1,\n",
      "                              'lr_decay_epoch': '40, 60',\n",
      "                              'lr_decay_period': 0,\n",
      "                              'lr_mode': 'step',\n",
      "                              'mixup': False,\n",
      "                              'mixup_alpha': 0.2,\n",
      "                              'mixup_off_epoch': 0,\n",
      "                              'mode': '',\n",
      "                              'momentum': 0.9,\n",
      "                              'no_wd': False,\n",
      "                              'num_training_samples': -1,\n",
      "                              'num_workers': 12,\n",
      "                              'output_lr_mult': 0.1,\n",
      "                              'pretrained_base': True,\n",
      "                              'rec_train': 'auto',\n",
      "                              'rec_train_idx': 'auto',\n",
      "                              'rec_val': 'auto',\n",
      "                              'rec_val_idx': 'auto',\n",
      "                              'resume_epoch': 0,\n",
      "                              'start_epoch': 0,\n",
      "                              'teacher': None,\n",
      "                              'temperature': 20,\n",
      "                              'transfer_lr_mult': 0.01,\n",
      "                              'use_rec': False,\n",
      "                              'warmup_epochs': 0,\n",
      "                              'warmup_lr': 0.0,\n",
      "                              'wd': 0.0001},\n",
      "                   'valid': {'batch_size': 8, 'num_workers': 12}},\n",
      "  'total_time': 610.0574655532837,\n",
      "  'train_acc': 0.7825,\n",
      "  'valid_acc': 0.8988603988603988}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 val acc: 0.899\n"
     ]
    }
   ],
   "source": [
    "hyperparameters={'model': model, 'batch_size': batch_size, 'lr': lr, 'epochs': 2}\n",
    "predictor = ImagePredictor()\n",
    "predictor.fit(shuffled_train_dataset, time_limit=60*10, hyperparameters=hyperparameters,\n",
    "              hyperparameter_tune_kwargs={'num_trials': 2})\n",
    "print('Top-1 val acc: %.3f' % predictor.fit_summary()['valid_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "78186932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 test acc: 0.902\n"
     ]
    }
   ],
   "source": [
    "test_acc = predictor.evaluate(test_dataset)\n",
    "print('Top-1 test acc: %.3f' % test_acc['top1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b8ccb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
